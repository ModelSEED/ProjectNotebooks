{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure KBase Jupyter Dev Environment\n",
    "<sub><sup>(contact chenry@anl.gov with questions)</sub></sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "print(\"python version \" + platform.python_version())\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "sys.path = [\"/scratch/shared/code/chenry_utility_module/lib\"] + sys.path\n",
    "from chenry_utility_module.kbdevutils import KBDevUtils\n",
    "kbdevutil = KBDevUtils(\"Ontology\")\n",
    "\n",
    "from modelseedpy import ModelSEEDBiochem\n",
    "from modelseedpy.core.mstemplate import MSTemplateBuilder\n",
    "from modelseedpy.core.annotationontology import convert_to_search_role,split_role\n",
    "from modelseedpy.helpers import get_template\n",
    "import cobra\n",
    "import cobrakbase\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "msrecon = kbdevutil.msseedrecon()\n",
    "annoapi = kbdevutil.anno_client(native_python_api=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing annotation comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = annoapi.get_annotation_ontology_events({\n",
    "    \"input_ref\" : \"154984/SwissProtCuratedProteins.RAST.Prokka.DRAM.Rhea\"\n",
    "})\n",
    "with open(kbdevutil.out_dir()+\"SwissProtAnnot.json\", 'w') as outfile:\n",
    "    json.dump(output, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biochem = ModelSEEDBiochem.get()\n",
    "domain_specific_lists = {\n",
    "    \"Fungi\" : \"154984/SwissProt_Rhea_Fungi\",\n",
    "    \"Other\" : \"154984/SwissProt_Rhea_Other\",\n",
    "    \"Viridiplantae\" : \"154984/SwissProt_Rhea_Viridiplantae\",\n",
    "    \"Archaea\" : \"154984/SwissProt_Rhea_Archaea\",\n",
    "    \"Bacteria\" : \"154984/SwissProt_Rhea_Bacteria\",\n",
    "    \"Metazoa\" : \"154984/SwissProt_Rhea_Metazoa\"\n",
    "}\n",
    "domain_proteins = {}\n",
    "for domain in domain_specific_lists:\n",
    "    data = kbdevutil.get_object(domain_specific_lists[domain])\n",
    "    for item in data[\"sequences\"]:\n",
    "        domain_proteins[item[\"id\"]] = domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the annotation ontology API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbdevutil = KBDevUtils(\"Ontology\",ws_version=\"appdev\")\n",
    "appdev_annoapi = kbdevutil.anno_client(native_python_api=True)\n",
    "with open('debug.json') as json_file:\n",
    "    input_data = json.load(json_file)\n",
    "output = anno_api.add_annotation_ontology_events(input_data)\n",
    "output = anno_api.get_annotation_ontology_events({\n",
    "    \"input_ref\" : \"102004/Methanosarcina_acetivorans_C2A_DRAM_RAST\"\n",
    "#    \"input_ref\" : \"93487/Ruepo_2orMoreRKM\"\n",
    "#    \"input_ref\" : \"77537/Sco_RAST_Prokka_BlastKOALA_PTools_DeepEC_DeepGO\"\n",
    "#    \"input_ref\" : \"77537/Sco_Union_BestUnion_2plus_Best2plus_RASTKEGG\"\n",
    "#    \"input_ref\" : \"77925/Pf5.6\"#,\n",
    "#    \"input_workspace\" : \n",
    "})\n",
    "with open('output.json', 'w') as outfile:\n",
    "    json.dump(output, outfile, indent=2)\n",
    "\n",
    "terms = ontology[\"events\"][0][\"ontology_terms\"]\n",
    "ontology[\"events\"][0][\"ontology_id\"] = \"SEED\"\n",
    "for gene in terms:\n",
    "    terms[gene][0][\"evidence\"] = \"test\"\n",
    "    terms[gene][0][\"term\"] = terms[gene][0][\"term\"].split(\":\")[1]\n",
    "    \n",
    "output = anno_api.add_annotation_ontology_events({\n",
    "    \"input_ref\" : \"GCF_000012265.1\",\n",
    "    \"input_workspace\" : 77925,\n",
    "    \"output_name\" : \"TestOntologyOutput\",\n",
    "    \"events\" : ontology[\"events\"],\n",
    "    \"output_workspace\": \"kimbrel1:narrative_1606152384556\",\n",
    "    \"save\" : 1\n",
    "})\n",
    "\n",
    "ontology = anno_api.get_annotation_ontology_events({\n",
    "    \"input_ref\" : \"TestOntologyOutput\",\n",
    "    \"input_workspace\" : \"kimbrel1:narrative_1606152384556\"\n",
    "})\n",
    "\n",
    "with open('/Users/chenry/output.json', 'w') as outfile:\n",
    "    json.dump(ontology, outfile, indent=2)\n",
    "\n",
    "#Escherichia_coli_K-12_MG1655\n",
    "#Synechocystis_PCC_6803\n",
    "#Methanosarcina_barkeri_Fusaro\n",
    "#Clostridium_beijerinckii_NCIMB_8052\n",
    "#Streptomyces_coelicolor_A3_2\n",
    "\n",
    "ontology_input = {\n",
    "    \"input_ref\":\"Streptomyces_coelicolor_A3_2\",\n",
    "    \"input_workspace\":\"chenry:narrative_1612295985064\",\n",
    "    \"output_name\":\"test\",\n",
    "    \"output_workspace\":\"chenry:narrative_1612295985064\",\n",
    "    \"clear_existing\":0,\n",
    "    \"overwrite_matching\":1,\n",
    "    \"save\":1,\n",
    "    \"events\":[\n",
    "        {\n",
    "            \"event_id\": \"annotate_genome:1.8.1:SSO:2020-11-23T17:51:18\",\n",
    "            \"original_description\": \"annotate_genome:2020-11-23T17:51:18:2020-11-23T17:51:18\",\n",
    "            \"description\": \"annotate_genome:2020-11-23T17:51:18:2020-11-23T17:51:18:2020-11-23T17:51:18\",\n",
    "            \"ontology_id\": \"SSO\",\n",
    "            \"method\": \"annotate_genome\",\n",
    "            \"method_version\": \"1.8.1\",\n",
    "            \"timestamp\": \"2020-11-23T17:51:18\",\n",
    "            \"ontology_terms\":{\"sgl0001\": [{\"term\": \"SSO:000001563\"}]}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "#with open('/Users/chenry/ontology_api_input.json') as json_file:\n",
    "#    ontology_input = json.load(json_file)\n",
    "#print(\"Loading ontology terms to genome!\")\n",
    "output = anno_api.add_annotation_ontology_events(ontology_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Published Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import cobra\n",
    "import cobrakbase\n",
    "kbase_api = cobrakbase.KBaseAPI()\n",
    "\n",
    "genome_list = [\"Sco\",\"Eco\",\"Cbe\",\"Mba\"]\n",
    "pub_model_hash = {\n",
    "    \"Sco\" : \"iMK1208\",\n",
    "    \"Eco\" : \"iML1515.kb\",\n",
    "    \"Cbe\" : \"iCM925_GF\",\n",
    "    \"Mba\" : \"iMG746_GF\"\n",
    "}\n",
    "pub_fba_hash = {\n",
    "    \"Sco\" : \"iMK1208_FBA\",\n",
    "    \"Eco\" : \"iML1515.kb_FBA\",\n",
    "    \"Cbe\" : \"iCM925_FBA\",\n",
    "    \"Mba\" : \"iMG746_FBA\"\n",
    "}\n",
    "pub_pheno_hash = {\n",
    "    \"Sco\" : \"iMK1208_Pheno\",\n",
    "    \"Eco\" : \"iML1515.kb_Pheno\",\n",
    "    \"Cbe\" : \"iCM925_Pheno\",\n",
    "    \"Mba\" : \"iMG746_Pheno\"\n",
    "}\n",
    "stats = {\n",
    "    \"Sco\":{},\"Eco\":{},\"Cbe\":{},\"Mba\":{}\n",
    "}\n",
    "types = [\"Best\",\"Union\",\"RAST\",\"Published\"]\n",
    "entities = [\"gene\",\"reaction\",\"pospheno\"]\n",
    "print(\"Species\\tType\\tReactions\\tGenes\\tGapfilled\\tBlocked\\tPospheno\\tGene match\\tReaction match\\tPheno match\")\n",
    "for genome in genome_list:\n",
    "    #Get:gene associated reactions;genes;gapfilled\n",
    "    models = [genome+\"_Best\",genome+\"_Union\",genome+\"_StdRAST_Mdl\",pub_model_hash[genome]]\n",
    "    count = 0\n",
    "    for model in models:\n",
    "        current_object = kbase_api.get_object(model,\"patrikd:narrative_1605639637696\")\n",
    "        stats[genome][types[count]] = {\n",
    "            \"reactions\":0,\n",
    "            \"gapfilled\":0,\n",
    "            \"blocked\":0,\n",
    "            \"genes\":0,\n",
    "            \"gene_hash\":{},\n",
    "            \"reaction_hash\":{},\n",
    "            \"pospheno\":0,\n",
    "            \"pospheno_hash\":{},\n",
    "            \"match_reaction\":0,\n",
    "            \"match_gene\":0,\n",
    "            \"match_pospheno\":0\n",
    "        }\n",
    "        for rxn in current_object[\"modelreactions\"]:\n",
    "            rxn[\"id\"] = rxn[\"id\"].replace(\"_z0\",\"_c0\")\n",
    "            if \"gapfill_data\" in rxn and len(rxn[\"gapfill_data\"]) > 0:\n",
    "                stats[genome][types[count]][\"gapfilled\"] += 1\n",
    "            elif count == 3 and len(rxn[\"modelReactionProteins\"]) == 0:\n",
    "                stats[genome][types[count]][\"gapfilled\"] += 1\n",
    "            if len(rxn[\"modelReactionProteins\"]) > 0:\n",
    "                stats[genome][types[count]][\"reactions\"] += 1\n",
    "                stats[genome][types[count]][\"reaction_hash\"][rxn[\"id\"]] = 1\n",
    "                for prot in rxn[\"modelReactionProteins\"]:\n",
    "                    for subunit in prot[\"modelReactionProteinSubunits\"]:\n",
    "                        for ftr in subunit[\"feature_refs\"]:\n",
    "                            ftr = ftr.split(\"/\").pop()\n",
    "                            stats[genome][types[count]][\"gene_hash\"][ftr] = 1             \n",
    "        stats[genome][types[count]][\"genes\"] = len(stats[genome][types[count]][\"gene_hash\"])\n",
    "        count += 1\n",
    "    \n",
    "    #Get:blocked\n",
    "    models = [genome+\"_Best_FBA\",genome+\"_Union_FBA\",genome+\"_StdRAST_FBA\",pub_fba_hash[genome]]\n",
    "    count = 0\n",
    "    for model in models:\n",
    "        current_object = kbase_api.get_object(model,\"patrikd:narrative_1605639637696\")\n",
    "        for var in current_object[\"FBAReactionVariables\"]:\n",
    "            if var[\"class\"] == \"Blocked\":\n",
    "                stats[genome][types[count]][\"blocked\"] += 1\n",
    "        count += 1\n",
    "    #Get:Neg;Pos\n",
    "    models = [genome+\"_Best_Pheno\",genome+\"_Union_Pheno\",genome+\"_StdRAST_Pheno\",pub_pheno_hash[genome]]\n",
    "    count = 0\n",
    "    for model in models:\n",
    "        if not (count == 3 and genome == \"Sco\"):\n",
    "            current_object = kbase_api.get_object(model,\"patrikd:narrative_1605639637696\")\n",
    "            for pheno in current_object[\"phenotypeSimulations\"]:\n",
    "                if pheno[\"simulatedGrowth\"] > 0:\n",
    "                    stats[genome][types[count]][\"pospheno_hash\"][pheno[\"id\"]] = 1\n",
    "                    stats[genome][types[count]][\"pospheno\"] += 1\n",
    "        count += 1   \n",
    "    #Computing matches\n",
    "    for entity in entities:\n",
    "        for count in range(0,3):\n",
    "            for entid in stats[genome][\"Published\"][entity+\"_hash\"]:\n",
    "                if entid in stats[genome][types[count]][entity+\"_hash\"]:\n",
    "                    stats[genome][types[count]][\"match_\"+entity] += 1\n",
    "    #Printing results\n",
    "    for currtype in types:\n",
    "        d = stats[genome][currtype]\n",
    "        print(genome+\"\\t\"+currtype+\"\\t\"+str(d[\"reactions\"])+\"\\t\"+str(d[\"genes\"])+\"\\t\"+str(d[\"gapfilled\"])\\\n",
    "            +\"\\t\"+str(d[\"blocked\"])+\"\\t\"+str(d[\"pospheno\"])+\"\\t\"+str(d[\"match_gene\"])+\"\\t\"+str(d[\"match_reaction\"])+\"\\t\"+str(d[\"match_pospheno\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Ontology API Against Gold Standard Genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import cobra\n",
    "import cobrakbase\n",
    "sys.path.append(\"/Users/chenry/code/MetabolicModelGapfilling/lib/\")\n",
    "#sys.path.append(\"/Users/chenry/code/annotation_ontology_api/lib\")\n",
    "from annotation_ontology_api.annotation_ontology_apiServiceClient import annotation_ontology_api\n",
    "#from annotation_ontology_api.annotation_ontology_api import AnnotationOntologyAPI\n",
    "\n",
    "#Test for ontology API\n",
    "kbase_api = cobrakbase.KBaseAPI()\n",
    "#anno_api = AnnotationOntologyAPI({\"data_directory\" : \"/Users/chenry/code/annotation_ontology_api/data/\"},kbase_api.ws_client,None)\n",
    "anno_api = annotation_ontology_api()\n",
    "genome_list = [\"Ani_RAST\"]\n",
    "#genome_list = [\"Sco_RAST\",\"Eco_RAST\",\"Cbe_RAST\",\"Syn_RAST\",\"Mba_RAST\"]\n",
    "genome_hash = {\n",
    "    \"Eco_RAST\": \"Eco_RAST_Prokka\",\n",
    "    \"Cbe_RAST\": \"Cbe_RAST_Prokka\",\n",
    "    \"Syn_RAST\": \"Syn_RAST_Prokka\",\n",
    "    \"Mba_RAST\": \"Mba_RAST_Prokka\",\n",
    "    \"Sco_RAST\": \"Sco_RAST_Prokka_BlastKOALA_PTools_DeepEC_DeepGO\",\n",
    "    \"Ani_RAST\": \"Ani_RAST_Prokka\"\n",
    "}\n",
    "for genome in genome_list:\n",
    "    print(genome)\n",
    "    ontology_output = anno_api.get_annotation_ontology_events({\n",
    "        \"input_ref\" : \"patrikd:narrative_1605639637696/\"+genome,\n",
    "    })\n",
    "    genome_object = kbase_api.get_object(genome,\"patrikd:narrative_1605639637696\")\n",
    "    ontology_input = {\n",
    "        \"input_ref\":genome_hash[genome],\n",
    "        \"input_workspace\":\"patrikd:narrative_1605639637696\",\n",
    "        \"output_name\":genome_hash[genome],\n",
    "        \"output_workspace\":\"patrikd:narrative_1605639637696\",        \n",
    "        \"save\":1,\n",
    "#        \"type\":\"KBaseGenomes.Genome\",\n",
    "#        \"object\":genome,\n",
    "        \"clear_existing\":0,\n",
    "        \"overwrite_matching\":1,\n",
    "        \"events\":[]\n",
    "    }\n",
    "    for event in ontology_output[\"events\"]:\n",
    "        print(event[\"ontology_id\"])\n",
    "        if event[\"ontology_id\"] == \"SSO\":\n",
    "            ontology_input[\"events\"].append(event)\n",
    "            break\n",
    "    \n",
    "    with open('/Users/chenry/output.json', 'w') as outfile:\n",
    "        json.dump(ontology_output, outfile, indent=2)\n",
    "    \n",
    "    if len(ontology_input[\"events\"]) == 1:\n",
    "        print(str(len(ontology_input[\"events\"])))\n",
    "        print(ontology_input[\"events\"][0][\"ontology_id\"])\n",
    "        ontology_output[\"events\"][0][\"method\"] = \"RAST annotation\"\n",
    "        ontology_output[\"events\"][0][\"description\"] = \"RAST annotation:\"+ontology_output[\"events\"][0][\"ontology_id\"]+\":\"+ontology_output[\"events\"][0][\"timestamp\"]    \n",
    "        ontology_output[\"events\"][0][\"ontology_terms\"] = {}\n",
    "        for ftr in genome_object[\"features\"]:\n",
    "            if \"functions\" in ftr:\n",
    "                for func in ftr[\"functions\"]:\n",
    "                    if ftr[\"id\"] not in ontology_input[\"events\"][0][\"ontology_terms\"]:\n",
    "                        ontology_input[\"events\"][0][\"ontology_terms\"][ftr[\"id\"]] = []\n",
    "                    ontology_input[\"events\"][0][\"ontology_terms\"][ftr[\"id\"]].append({\n",
    "                        \"term\": \"SSO:\"+func\n",
    "                    })\n",
    "        for ftr in genome_object[\"cdss\"]:\n",
    "            if \"functions\" in ftr:\n",
    "                for func in ftr[\"functions\"]:\n",
    "                    if ftr[\"id\"] not in ontology_input[\"events\"][0][\"ontology_terms\"]:\n",
    "                        ontology_input[\"events\"][0][\"ontology_terms\"][ftr[\"id\"]] = []\n",
    "                    ontology_input[\"events\"][0][\"ontology_terms\"][ftr[\"id\"]].append({\n",
    "                        \"term\": \"SSO:\"+func\n",
    "                    })\n",
    "        ontology_output = anno_api.add_annotation_ontology_events(ontology_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing SSO reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing Super Annotated E. coli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/chenry/code/cb_annotation_ontology_api/lib\")\n",
    "import os\n",
    "import cobra\n",
    "import cobrakbase\n",
    "import json\n",
    "import csv\n",
    "import logging\n",
    "import cplex\n",
    "import optlang\n",
    "import re\n",
    "import pandas as pd\n",
    "from optlang.symbolics import Zero, add\n",
    "import cobra.util.solver as sutil\n",
    "from cobrakbase.core.converters import KBaseFBAModelToCobraBuilder\n",
    "from cobrakbase.Workspace.WorkspaceClient import Workspace as WorkspaceClient\n",
    "from annotation_ontology_api.annotation_ontology_api import AnnotationOntologyAPI\n",
    "from cobra.core.dictlist import DictList\n",
    "from cobra.core import Gene, Metabolite, Model, Reaction\n",
    "from IPython.core.display import HTML\n",
    "#Test for ontology API\n",
    "kbase_api = cobrakbase.KBaseAPI()\n",
    "anno_api = AnnotationOntologyAPI({\"data_directory\" : \"/Users/chenry/code/cb_annotation_ontology_api/data/\"},\n",
    "    kbase_api.ws_client,None)\n",
    "\n",
    "output = anno_api.get_annotation_ontology_events({\n",
    "    \"input_ref\" : \"Eco_Union_BestUnion_2plus_Best2plus_RASTKEGG.pdb\",\n",
    "    \"input_workspace\" : 133085\n",
    "})\n",
    "with open('EcoliSuperAnnotation', 'w') as outfile:\n",
    "    json.dump(output, outfile, indent=2)\n",
    "#Print annotations in tabular form\n",
    "annotations = {}\n",
    "for event in output[\"events\"]:\n",
    "    name = None\n",
    "    if event[\"original_description\"][0:4] == \"RAST\":\n",
    "        name = \"RAST\"\n",
    "    elif event[\"original_description\"][0:6] == \"Prokka\":\n",
    "        name = \"Prokka\"\n",
    "    elif event[\"original_description\"][0:5] == \"Blast\":\n",
    "        name = \"Koala\"\n",
    "    elif event[\"original_description\"][0:7] == \"Pathway\":\n",
    "        name = \"PathwayTools\"\n",
    "    elif event[\"original_description\"][0:6] == \"DeepEC\":\n",
    "        name = \"DeepEC\"\n",
    "    elif event[\"original_description\"][0:6] == \"DeepGO\":\n",
    "        name = \"DeepGO\"\n",
    "    elif event[\"original_description\"][0:3] == \"KBA\":\n",
    "        name = \"PDB\"\n",
    "    if name:\n",
    "        for gene in event[\"ontology_terms\"]:\n",
    "            for item in event[\"ontology_terms\"][gene]:\n",
    "                if \"modelseed_ids\" in item:\n",
    "                    if gene not in annotations:\n",
    "                        annotations[gene] = {}\n",
    "                    for msid in item[\"modelseed_ids\"]:\n",
    "                        if msid not in annotations[gene]:\n",
    "                            annotations[gene][msid] = {}\n",
    "                        if name not in annotations[gene][msid]:\n",
    "                            annotations[gene][msid][name] = []\n",
    "                        if item[\"term\"] not in annotations[gene][msid][name]:\n",
    "                            annotations[gene][msid][name].append(item[\"term\"])\n",
    "#Loading and saving dataframe\n",
    "annos = [\"RAST\",\"Prokka\",\"Koala\",\"PathwayTools\",\"DeepEC\",\"DeepGO\",\"PDB\"]\n",
    "data = {\"Gene\":[],\"Reactions\":[],\"RAST\":[],\"Prokka\":[],\"Koala\":[],\"PathwayTools\":[],\"DeepEC\":[],\"DeepGO\":[],\"PDB\":[]}\n",
    "for gene in annotations:\n",
    "    for rxn in annotations[gene]:\n",
    "        data[\"Gene\"].append(gene)\n",
    "        data[\"Reactions\"].append(rxn)\n",
    "        for anno in annos:\n",
    "            if anno in annotations[gene][rxn]:\n",
    "                data[anno].append(\",\".join(annotations[gene][rxn][anno]))\n",
    "            else:\n",
    "                data[anno].append(None)\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"EcoliSuperAnnotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology = anno_api.get_annotation_ontology_events({\n",
    "    \"input_ref\" : \"Pf5.6\",\n",
    "    \"input_workspace\" : 77925\n",
    "})\n",
    "with open('/Users/chenry/translation.json', 'w') as outfile:\n",
    "    json.dump(anno_api.alias_hash, outfile, indent=2)\n",
    "with open('/Users/chenry/output.json', 'w') as outfile:\n",
    "    json.dump(ontology, outfile, indent=2)\n",
    "\n",
    "terms = ontology[\"events\"][0][\"ontology_terms\"]\n",
    "ontology[\"events\"][0][\"ontology_id\"] = \"SEED\"\n",
    "for gene in terms:\n",
    "    terms[gene][0][\"evidence\"] = \"test\"\n",
    "    terms[gene][0][\"term\"] = terms[gene][0][\"term\"].split(\":\")[1]\n",
    "    \n",
    "with open('/Users/chenry/output2.json', 'w') as outfile:\n",
    "    json.dump(ontology, outfile, indent=2)\n",
    "    \n",
    "output = anno_api.add_annotation_ontology_events({\n",
    "    \"input_ref\" : \"GCF_000012265.1\",\n",
    "    \"input_workspace\" : 77925,\n",
    "    \"output_name\" : \"TestOntologyOutput\",\n",
    "    \"events\" : ontology[\"events\"],\n",
    "    \"output_workspace\": \"kimbrel1:narrative_1606152384556\",\n",
    "    \"save\" : 1\n",
    "})\n",
    "\n",
    "#with open('/Users/chenry/genome.json', 'w') as outfile:\n",
    "#    json.dump(output[\"object\"], outfile, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not sure what this code is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sso_hash = dict()\n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/genome_sso.json') as json_file:\n",
    "    sso_hash = json.load(json_file)\n",
    "\n",
    "sso_template = dict()\n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/SSO_reactions.json') as json_file:\n",
    "    sso_template = json.load(json_file)\n",
    "\n",
    "reaction_hash = dict()\n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/genome_reactions.json') as json_file:\n",
    "    reaction_hash = json.load(json_file)\n",
    "\n",
    "function_hash = dict()\n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/genome_functions.json') as json_file:\n",
    "    function_hash = json.load(json_file)\n",
    "\n",
    "functions = dict()\n",
    "comparison = dict()\n",
    "for genome in sso_hash:\n",
    "    if genome in reaction_hash:\n",
    "        sso_based_reactions = dict()\n",
    "        sso_based_genes = dict()\n",
    "        for gene in sso_hash[genome]:\n",
    "            for sso in sso_hash[genome][gene]:\n",
    "                if sso in sso_template:\n",
    "                    for reaction in sso_template[sso]:\n",
    "                        if reaction not in sso_based_reactions:\n",
    "                            sso_based_reactions[reaction] = dict()\n",
    "                        sso_based_reactions[reaction][gene] = 1\n",
    "                        if gene not in sso_based_genes:\n",
    "                            sso_based_genes[gene] = dict()\n",
    "                        sso_based_genes[gene][reaction] = 1\n",
    "        comparison[genome] = {\n",
    "            \"SSO_reactions\": len(sso_based_reactions),\n",
    "            \"SSO_genes\": len(sso_based_genes),\n",
    "            \"Extra_SS_reactions\": [],\n",
    "            \"Extra_SS_genes\": [],\n",
    "            \"Extra_MS_reactions\": [],\n",
    "            \"Extra_MS_genes\": [],\n",
    "            \"Extra_SS_reactions_counts\": 0,\n",
    "            \"Extra_SS_genes_counts\": 0,\n",
    "            \"Extra_MS_reactions_counts\": 0,\n",
    "            \"Extra_MS_genes_counts\": 0,\n",
    "            \"MS_reactions\": len(reaction_hash[genome]),\n",
    "            \"MS_genes\" 0,\n",
    "        }\n",
    "        ms_based_genes = dict()\n",
    "        for reaction in reaction_hash[genome]:\n",
    "            if reaction not in sso_based_reactions:\n",
    "                comparison[genome][\"Extra_MS_reactions\"].append(reaction)\n",
    "                comparison[genome][\"Extra_MS_reactions_counts\"] += 1\n",
    "            for gene in reaction_hash[genome][reaction]:\n",
    "                if gene not in ms_based_genes:\n",
    "                    ms_based_genes[gene] = dict()\n",
    "                ms_based_genes[gene][reaction] = 1\n",
    "        for reaction in sso_based_reactions:\n",
    "            if reaction not in reaction_hash[genome]:\n",
    "                comparison[genome][\"Extra_SS_reactions\"].append(reaction)\n",
    "                comparison[genome][\"Extra_SS_reactions_counts\"] += 1\n",
    "        comparison[genome][\"MS_genes\"] = len(ms_based_genes)\n",
    "        for gene in ms_based_genes:\n",
    "            if gene not in sso_based_genes:\n",
    "                comparison[genome][\"Extra_MS_genes\"].append(gene)\n",
    "                comparison[genome][\"Extra_MS_genes_counts\"] += 1\n",
    "        for gene in sso_based_genes:\n",
    "            if gene not in ms_based_genes:\n",
    "                comparison[genome][\"Extra_SS_genes\"].append(gene)\n",
    "                comparison[genome][\"Extra_SS_genes_counts\"] += 1\n",
    "            \n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/comparison.json', 'w') as outfile:\n",
    "    json.dump(comparison, outfile)\n",
    "    \n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/problem_functions.json', 'w') as outfile:\n",
    "    json.dump(functions, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing reaction gene associations from all models in workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = msrecon.kbase_api.list_objects(\"chenry:narrative_1581959452634\")\n",
    "reaction_hash = dict()\n",
    "count = 0\n",
    "for obj in objects:\n",
    "    if obj[1][-14:] == \".RAST.mdl.base\":\n",
    "        count += 1\n",
    "        genomeid = obj[1][0:-14]\n",
    "        reaction_hash[genomeid] = dict()\n",
    "        model = kbase.get_from_ws(obj[1],\"chenry:narrative_1581959452634\")\n",
    "        for rxn in model.reactions:\n",
    "            reaction_hash[genomeid][rxn.id.split(\"_\")[0]] = dict()\n",
    "            for prot in rxn.data[\"modelReactionProteins\"]:\n",
    "                for subunit in prot[\"modelReactionProteinSubunits\"]:\n",
    "                    for ftr in subunit[\"feature_refs\"]:\n",
    "                        ftrid = ftr.split(\"/\").pop()\n",
    "                        reaction_hash[genomeid][rxn.id.split(\"_\")[0]][ftrid] = 0\n",
    "\n",
    "with open(kbdevutil.out_dir()+\"genome_reactions.json\", 'w') as outfile:\n",
    "    json.dump(reaction_hash, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_ModelSEED",
   "language": "python",
   "name": "python3_modelseed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
