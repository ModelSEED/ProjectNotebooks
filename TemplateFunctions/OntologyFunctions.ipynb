{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure KBase Jupyter Dev Environment\n",
    "<sub><sup>(contact chenry@anl.gov with questions)</sub></sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version 3.11.1\n",
      "KBBaseModules 0.0.1\n",
      "Output files printed to:/home/chenry/scratch/Ontology/ when using KBDevUtils.out_dir()\n",
      "modelseedpy 0.3.3\n",
      "cobrakbase 0.3.1\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(\"python version \" + platform.python_version())\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import requests\n",
    "\n",
    "sys.path = [\"/scratch/shared/code/chenry_utility_module/lib\"] + sys.path\n",
    "from chenry_utility_module.kbdevutils import KBDevUtils\n",
    "kbdevutil = KBDevUtils(\"Ontology\")\n",
    "\n",
    "from modelseedpy import ModelSEEDBiochem\n",
    "from modelseedpy.core.mstemplate import MSTemplateBuilder\n",
    "from modelseedpy.core.annotationontology import convert_to_search_role, split_role\n",
    "from modelseedpy.helpers import get_template\n",
    "import cobra\n",
    "import cobrakbase\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "msrecon = kbdevutil.msseedrecon()\n",
    "annoapi = kbdevutil.anno_client(native_python_api=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling and printing ontology terms from a target genome using ontology API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = annoapi.get_annotation_ontology_events({\n",
    "    \"input_ref\" : \"154984/SwissProtCuratedProteins.RAST.Prokka.DRAM.Rhea\"\n",
    "})\n",
    "with open(kbdevutil.out_dir()+\"SwissProtAnnot.json\", 'w') as outfile:\n",
    "    json.dump(output, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing annotation comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32100/32100 [00:01<00:00, 29979.48it/s]\n",
      "100%|██████████| 32100/32100 [00:01<00:00, 31226.10it/s]\n",
      "100%|██████████| 32100/32100 [00:00<00:00, 56964.56it/s]\n",
      "100%|██████████| 32100/32100 [00:01<00:00, 18808.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered reaction counts: {'RAST': 0, 'DRAM_KO': 0, 'DRAM_EC': 0, 'Prokka': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3076/3076 [1:21:35<00:00,  1.59s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ms_data = {}\n",
    "rhea_data = {}\n",
    "class_counts = {}\n",
    "ec_hash = {}\n",
    "\n",
    "with open('/scratch/shared/code/cb_annotation_ontology_api/data/GO_dictionary.json') as json_file:\n",
    "    go_dictionary = json.load(json_file)\n",
    "\n",
    "reaction_ec = pd.read_csv(\"/scratch/shared/data/ModelSEEDDatabase/Biochemistry/Aliases/Unique_ModelSEED_Reaction_ECs.txt\",sep=\"\\t\")\n",
    "rxn_ec = {}\n",
    "for [i,row] in reaction_ec.iterrows():\n",
    "    if row[\"External ID\"] not in ec_hash:\n",
    "        ec_hash[row[\"External ID\"]] = {}\n",
    "    if \"MS\" not in ec_hash[row[\"External ID\"]]:\n",
    "        ec_hash[row[\"External ID\"]][\"MS\"] = {}\n",
    "    if row[\"ModelSEED ID\"] not in ec_hash[row[\"External ID\"]][\"MS\"]:\n",
    "        ec_hash[row[\"External ID\"]][\"MS\"][row[\"ModelSEED ID\"]] = 1\n",
    "    if row[\"ModelSEED ID\"] not in rxn_ec:\n",
    "        rxn_ec[row[\"ModelSEED ID\"]] = {}\n",
    "    if row[\"External ID\"] not in rxn_ec[row[\"ModelSEED ID\"]]:\n",
    "        rxn_ec[row[\"ModelSEED ID\"]][row[\"External ID\"]] = 1\n",
    "\n",
    "ec_trans = pd.read_csv(\"/scratch/shared/data/TemplateFunctions/rhea2ec.tsv\",sep=\"\\t\")\n",
    "for [i,row] in ec_trans.iterrows():\n",
    "    row[\"RHEA_ID\"] = str(row[\"RHEA_ID\"])\n",
    "    if row[\"RHEA_ID\"] not in rhea_data:\n",
    "        rhea_data[row[\"RHEA_ID\"]] = {\n",
    "            \"id\":row[\"RHEA_ID\"],\n",
    "            \"ec\":[],\n",
    "            \"name\":None,\n",
    "            \"genes\":[],\n",
    "            \"msrxn\":[]\n",
    "        }\n",
    "    if row[\"ID\"] not in rhea_data[row[\"RHEA_ID\"]][\"ec\"]:\n",
    "        rhea_data[row[\"RHEA_ID\"]][\"ec\"].append(row[\"ID\"])\n",
    "    if row[\"ID\"] not in ec_hash:\n",
    "        ec_hash[row[\"ID\"]] = {}\n",
    "    if \"RHEA\" not in ec_hash[row[\"ID\"]]:\n",
    "        ec_hash[row[\"ID\"]][\"RHEA\"] = {}\n",
    "    if row[\"RHEA_ID\"] not in ec_hash[row[\"ID\"]][\"RHEA\"]:\n",
    "        ec_hash[row[\"ID\"]][\"RHEA\"][row[\"RHEA_ID\"]] = True\n",
    "\n",
    "ec_trans = pd.read_csv(\"/scratch/shared/data/TemplateFunctions/rhea-ec-iubmb.tsv\",sep=\"\\t\")\n",
    "for [i,row] in ec_trans.iterrows():\n",
    "    row[\"RHEA_ID\"] = str(row[\"RHEA_ID\"])\n",
    "    if row[\"RHEA_ID\"] not in rhea_data:\n",
    "        rhea_data[row[\"RHEA_ID\"]] = {\n",
    "            \"id\":row[\"RHEA_ID\"],\n",
    "            \"ec\":[],\n",
    "            \"name\":None,\n",
    "            \"genes\":[],\n",
    "            \"msrxn\":[]\n",
    "        }\n",
    "    if row[\"EC\"] not in rhea_data[row[\"RHEA_ID\"]][\"ec\"]:\n",
    "        rhea_data[row[\"RHEA_ID\"]][\"ec\"].append(row[\"EC\"])\n",
    "    if row[\"EC\"] not in ec_hash:\n",
    "        ec_hash[row[\"EC\"]] = {}\n",
    "    if \"MS\" not in ec_hash[row[\"EC\"]]:\n",
    "        ec_hash[row[\"EC\"]][\"RHEA\"] = {}\n",
    "    if row[\"RHEA_ID\"] not in ec_hash[row[\"EC\"]][\"RHEA\"]:\n",
    "        ec_hash[row[\"EC\"]][\"RHEA\"][row[\"RHEA_ID\"]] = True\n",
    "                                            \n",
    "go_trans = pd.read_csv(\"/scratch/shared/data/TemplateFunctions/rhea2go.tsv\",sep=\"\\t\")\n",
    "for [i,row] in go_trans.iterrows():\n",
    "    row[\"RHEA_ID\"] = str(row[\"RHEA_ID\"])\n",
    "    if row[\"RHEA_ID\"] not in rhea_data:\n",
    "        rhea_data[row[\"RHEA_ID\"]] = {\n",
    "            \"id\":row[\"RHEA_ID\"],\n",
    "            \"ec\":[],\n",
    "            \"name\":None,\n",
    "            \"genes\":[],\n",
    "            \"msrxn\":[]\n",
    "        }\n",
    "    rhea_data[row[\"RHEA_ID\"]][\"name\"] = row[\"ID\"]\n",
    "    if row[\"ID\"] in go_dictionary[\"term_hash\"]:\n",
    "        rhea_data[row[\"RHEA_ID\"]][\"name\"] += \":\"+go_dictionary[\"term_hash\"][row[\"ID\"]][\"name\"]\n",
    "\n",
    "def get_ms_data(id):\n",
    "    if id[0:6] == \"MSRXN:\":\n",
    "        id = id[6:]\n",
    "    if id not in ms_data:\n",
    "        ms_data[id] = {\"id\":id,\"equation\":\"\",\"name\":\"\",\"ec\":\"\"}\n",
    "        if id in biochem.reactions:\n",
    "            rxnobj = biochem.reactions.get_by_id(id)\n",
    "            ms_data[id][\"equation\"] = rxnobj.build_reaction_string(use_metabolite_names=True)\n",
    "            ms_data[id][\"name\"] = rxnobj.name\n",
    "            ms_data[id][\"ec\"] = rxnobj.ec_numbers\n",
    "    return ms_data[id]\n",
    "\n",
    "def get_rhea_data(rhea_id):\n",
    "    if rhea_id[0:4] == \"RHEA\":\n",
    "        rhea_id = rhea_id[5:]\n",
    "    if rhea_id not in rhea_data:\n",
    "        rhea_data[rhea_id] = {\"id\":rhea_id,\"ec\":\"\",\"name\":\"\",\"genes\":[],\"msrxn\":[]}\n",
    "        rhea_data[\"RHEA:\"+rhea_id] = rhea_data[rhea_id]\n",
    "    return rhea_data[rhea_id]\n",
    "\n",
    "biochem = ModelSEEDBiochem.get()\n",
    "\n",
    "with open(kbdevutil.out_dir()+\"SwissProtAnnot.json\") as json_file:\n",
    "    output = json.load(json_file)\n",
    "\n",
    "filtered_reactions = pd.read_csv(\"/scratch/shared/code/cb_annotation_ontology_api/data/FilteredReactions.csv\")\n",
    "filtered_reaction_hash = {}\n",
    "for [i,row] in filtered_reactions.iterrows():\n",
    "    filtered_reaction_hash[row[\"id\"]] = True\n",
    "\n",
    "with open(kbdevutil.out_dir()+\"SwissProtAnnot.json\") as json_file:\n",
    "    output = json.load(json_file)\n",
    "\n",
    "with open('/scratch/shared/code/cb_annotation_ontology_api/data/SSO_dictionary.json') as json_file:\n",
    "    sso = json.load(json_file)\n",
    "\n",
    "with open(\"/scratch/shared/code/cb_annotation_ontology_api/data/obsolete_ec.json\") as json_file:\n",
    "    obs_ec = json.load(json_file)\n",
    "\n",
    "def trans_ec(ec):\n",
    "    original_ec = ec\n",
    "    count=0\n",
    "    while ec in obs_ec:\n",
    "        count += 1\n",
    "        if count == 20:\n",
    "            #print(\"Circular reference:\",original_ec,\"->\",ec)\n",
    "            return original_ec\n",
    "        ec = obs_ec[ec]\n",
    "    return ec\n",
    "\n",
    "domain_specific_lists = {\n",
    "    \"Fungi\" : \"154984/SwissProt_Rhea_Fungi\",\n",
    "    \"Other\" : \"154984/SwissProt_Rhea_Other\",\n",
    "    \"Viridiplantae\" : \"154984/SwissProt_Rhea_Viridiplantae\",\n",
    "    \"Archaea\" : \"154984/SwissProt_Rhea_Archaea\",\n",
    "    \"Bacteria\" : \"154984/SwissProt_Rhea_Bacteria\",\n",
    "    \"Metazoa\" : \"154984/SwissProt_Rhea_Metazoa\"\n",
    "}\n",
    "domain_proteins = {}\n",
    "for domain in domain_specific_lists:\n",
    "    data = kbdevutil.get_object(domain_specific_lists[domain])\n",
    "    #with open(kbdevutil.out_dir()+domain+\".json\", 'w') as outfile:\n",
    "    #    json.dump(data, outfile)\n",
    "    for item in data[\"data\"][\"sequences\"]:\n",
    "        domain_proteins[item[\"id\"]] = domain\n",
    "\n",
    "event_hash = {}\n",
    "annotations_by_gene = {}\n",
    "filtered_reaction_count = {}\n",
    "for event in output[\"events\"]:\n",
    "    if event[\"event_id\"][0:4] == \"RAST\":\n",
    "        for gene in event[\"ontology_terms\"]:\n",
    "            if gene not in annotations_by_gene:\n",
    "                annotations_by_gene[gene] = {}\n",
    "            annotations_by_gene[gene][\"RAST\"] = event[\"ontology_terms\"][gene]\n",
    "    elif event[\"event_id\"][0:7] == \"DRAM:KO\":\n",
    "        for gene in event[\"ontology_terms\"]:\n",
    "            if gene not in annotations_by_gene:\n",
    "                annotations_by_gene[gene] = {}\n",
    "            annotations_by_gene[gene][\"DRAM_KO\"] = event[\"ontology_terms\"][gene]\n",
    "    elif event[\"event_id\"][0:7] == \"DRAM:EC\":\n",
    "        for gene in event[\"ontology_terms\"]:\n",
    "            if gene not in annotations_by_gene:\n",
    "                annotations_by_gene[gene] = {}\n",
    "            annotations_by_gene[gene][\"DRAM_EC\"] = event[\"ontology_terms\"][gene]\n",
    "    elif event[\"id\"][0:4] == \"RHEA\":\n",
    "        for gene in event[\"ontology_terms\"]:\n",
    "            if gene not in annotations_by_gene:\n",
    "                annotations_by_gene[gene] = {}\n",
    "            annotations_by_gene[gene][\"Rhea\"] = event[\"ontology_terms\"][gene]\n",
    "    elif event[\"event_id\"][0:6] == \"Prokka\":\n",
    "        for gene in event[\"ontology_terms\"]:\n",
    "            if gene not in annotations_by_gene:\n",
    "                annotations_by_gene[gene] = {}\n",
    "            annotations_by_gene[gene][\"Prokka\"] = event[\"ontology_terms\"][gene]\n",
    "\n",
    "list = [\"RAST\", \"DRAM_KO\", \"DRAM_EC\", \"Prokka\"]\n",
    "all_data = {\"Rhea\":rhea_data}\n",
    "for current in list:\n",
    "    data = []\n",
    "    class_counts[current] = {}\n",
    "    filtered_reaction_count[current] = 0\n",
    "    all_data[current] = {}\n",
    "    for gene in tqdm(annotations_by_gene):\n",
    "        if gene[-4:] == \".CDS\":\n",
    "            continue\n",
    "        current_row = {\"Gene\": gene,\"Domain\": \"None\",\"Class\":\"Missmatch\",\"Extra_SP\":0,\"Extra_\"+current:0,\"SP_RHID\": None,\"SP_EC\":None,\"SP_RHGO\":None,\"SP_MSID\": None,\"SP_MSName\":None,\"SP_MSEquation\":None,current: None,current+\"_MSID\": None,current+\"_MSName\": None,current+\"_MSEquation\": None,current+\"_MSEC\": None}\n",
    "        data.append(current_row)\n",
    "        spmsid = {}\n",
    "        sp_ec = []\n",
    "        current_ec = []\n",
    "        if gene in domain_proteins:\n",
    "            current_row[\"Domain\"] = domain_proteins[gene]\n",
    "        if current_row[\"Domain\"] not in class_counts[current]:\n",
    "            class_counts[current][current_row[\"Domain\"]] = {}\n",
    "        if \"Rhea\" in annotations_by_gene[gene]:\n",
    "            for item in annotations_by_gene[gene][\"Rhea\"]:\n",
    "                current_rhea = get_rhea_data(item[\"term\"])\n",
    "                for i,ec in enumerate(current_rhea[\"ec\"]):\n",
    "                    current_rhea[\"ec\"][i] = trans_ec(ec)  \n",
    "                for column in [\"GO\",\"ID\"]:\n",
    "                    label = \"SP_RH\"+column\n",
    "                    if current_row[label] and len(current_row[label]) > 0:\n",
    "                        current_row[label] += \"\\n\"\n",
    "                    else:\n",
    "                        current_row[label] = \"\"\n",
    "                    if column.lower() in current_rhea:\n",
    "                        if current_rhea[column.lower()]:\n",
    "                            current_row[label] += current_rhea[column.lower()]\n",
    "                current_ms = None\n",
    "                current_rhea[\"genes\"].append(gene)\n",
    "                if \"modelseed_ids\" in item:\n",
    "                    current_rhea[\"msrxn\"].append(item[\"modelseed_ids\"][0])\n",
    "                    current_ms = get_ms_data(item[\"modelseed_ids\"][0])\n",
    "                    if item[\"modelseed_ids\"][0] in filtered_reaction_hash and current == \"RAST\":\n",
    "                        filtered_reaction_count[\"Rhea\"] += 1\n",
    "                    for ec in current_ms[\"ec\"]:\n",
    "                        ec = trans_ec(ec)\n",
    "                for column in [\"Name\",\"Equation\",\"ID\"]:\n",
    "                    label = \"SP_MS\"+column\n",
    "                    if current_row[label] and len(current_row[label]) > 0:\n",
    "                        current_row[label] += \"\\n\"\n",
    "                    else:\n",
    "                        current_row[label] = \"\"\n",
    "                    if current_ms:\n",
    "                        spmsid[item[\"modelseed_ids\"][0]] = False\n",
    "                        if column.lower() in current_ms:\n",
    "                            current_row[label] += current_ms[column.lower()]\n",
    "                if current_row[\"SP_EC\"] and len(current_row[\"SP_EC\"]) > 0:\n",
    "                    current_row[\"SP_EC\"] += \"\\n\"\n",
    "                else:\n",
    "                    current_row[\"SP_EC\"] = \"\"\n",
    "                current_row[\"SP_EC\"] = \"/\".join(current_rhea[\"ec\"])\n",
    "        if current in annotations_by_gene[gene]:\n",
    "            for item in annotations_by_gene[gene][current]:\n",
    "                if item[\"term\"] not in all_data[current]:\n",
    "                    all_data[current][item[\"term\"]] = {\"name\":None,\"ec\":[],\"msrxn\":[],\"id\":item[\"term\"],\"genes\":[]}\n",
    "                all_data[current][item[\"term\"]][\"genes\"].append(gene)\n",
    "                if current_row[current] and len(current_row[current]) > 0:\n",
    "                    current_row[current] += \"\\n\"\n",
    "                else:\n",
    "                    current_row[current] = \"\"\n",
    "                current_row[current] += item[\"term\"]\n",
    "                if current_row[current] == \"SSO:000009137\":\n",
    "                    current_row[\"Class\"] = \"hypothetical\"\n",
    "                if item[\"term\"] in sso[\"term_hash\"]:\n",
    "                    all_data[current][item[\"term\"]][\"name\"] = sso[\"term_hash\"][item[\"term\"]][\"name\"]\n",
    "                    current_row[current] += \":\"+sso[\"term_hash\"][item[\"term\"]][\"name\"]\n",
    "                match = re.search(r'(\\d+\\.[\\d-]+\\.[\\d-]+\\.[\\d-]+)',current_row[current])\n",
    "                if match:\n",
    "                    ec = match.group(0)\n",
    "                    ec = trans_ec(ec)\n",
    "                    current_ec.append(ec)\n",
    "                    if ec not in all_data[current][item[\"term\"]][\"ec\"]:\n",
    "                        all_data[current][item[\"term\"]][\"ec\"].append(ec)\n",
    "                    if ec not in ec_hash:\n",
    "                        ec_hash[ec] = {}\n",
    "                    if current not in ec_hash[ec]:\n",
    "                        ec_hash[ec][current] = {}\n",
    "                    if item[\"term\"] not in ec_hash[ec][current]:\n",
    "                        ec_hash[ec][current][item[\"term\"]] = True\n",
    "                    if ec in sp_ec:\n",
    "                        if current_row[\"Class\"] == \"Missmatch\":\n",
    "                            current_row[\"Class\"] = \"ec match\"\n",
    "                for column in [\"Name\",\"Equation\",\"ID\",\"EC\"]:\n",
    "                    label = current+\"_MS\"+column\n",
    "                    if current_row[label] and len(current_row[label]) > 0:\n",
    "                        current_row[label] += \"\\n\"\n",
    "                    else:\n",
    "                        current_row[label] = \"\"\n",
    "                    if \"modelseed_ids\" in item:\n",
    "                        first = True\n",
    "                        for msrxn in item[\"modelseed_ids\"]:\n",
    "                            all_data[current][item[\"term\"]][\"msrxn\"].append(msrxn)\n",
    "                            if msrxn in filtered_reaction_hash:\n",
    "                                filtered_reaction_count[current] += 1\n",
    "                            if msrxn in spmsid:\n",
    "                                current_row[\"Class\"] = \"full match\"\n",
    "                                spmsid[msrxn] = True\n",
    "                            elif column == \"Name\":\n",
    "                                current_row[\"Extra_\"+current] += 1\n",
    "                            current_ms = get_ms_data(msrxn)\n",
    "                            if column.lower() in current_ms:\n",
    "                                if column == \"EC\":\n",
    "                                    current_row[label] += \"/\".join(current_ms[column.lower()])\n",
    "                                    for ec in current_ms[column.lower()]:\n",
    "                                        ec = trans_ec(ec)\n",
    "                                        if ec not in current_ec:\n",
    "                                            current_ec.append(ec)\n",
    "                                        if ec in sp_ec:\n",
    "                                            if current_row[\"Class\"] == \"Missmatch\":\n",
    "                                                current_row[\"Class\"] = \"ec match\"\n",
    "                                else:\n",
    "                                    if column == \"Name\":\n",
    "                                        all_data[current][item[\"term\"]][\"name\"] = current_ms[\"name\"]\n",
    "                                    current_row[label] += current_ms[column.lower()]\n",
    "                            if not first:\n",
    "                                current_row[current] += \"\\n\"#Making sure SSOs align with MSRXNs\n",
    "                            first = False\n",
    "        else:\n",
    "            current_row[\"Class\"] = \"Unannotated\"\n",
    "        if current_row[\"Class\"] == \"Missmatch\":\n",
    "            if len(sp_ec) == 0:\n",
    "                current_row[\"Class\"] = \"No rhea EC\"\n",
    "            elif len(current_ec) == 0:\n",
    "                current_row[\"Class\"] = \"No other EC\"\n",
    "        for msid in spmsid:\n",
    "            if not spmsid[msid]:\n",
    "                current_row[\"Extra_SP\"] += 1\n",
    "        if current_row[\"Class\"] not in class_counts[current][current_row[\"Domain\"]]:\n",
    "            class_counts[current][current_row[\"Domain\"]][current_row[\"Class\"]] = 0\n",
    "        class_counts[current][current_row[\"Domain\"]][current_row[\"Class\"]] += 1\n",
    "    df = pd.DataFrame.from_records(data)\n",
    "    df.to_csv(kbdevutil.out_dir()+current+\"_annotations.tsv\", sep='\\t', index=False)\n",
    "    with open(kbdevutil.out_dir()+\"ClassCounts.json\", 'w') as outfile:\n",
    "        json.dump(class_counts, outfile)\n",
    "    #Converting class_counts into dataframe for printing as a table\n",
    "    all_records = []\n",
    "    for anno in class_counts:\n",
    "        for domain in class_counts[anno]:\n",
    "            record = {\"Domain\":domain,\"Algorithm\":anno}\n",
    "            for class_type in class_counts[anno][domain]:\n",
    "                record[class_type] = class_counts[anno][domain][class_type]\n",
    "            all_records.append(record)\n",
    "    df = pd.DataFrame.from_records(all_records)\n",
    "    df.to_csv(kbdevutil.out_dir()+\"ClassCounts.tsv\", sep='\\t', index=False)\n",
    "\n",
    "print(\"Filtered reaction counts:\",str(filtered_reaction_count))\n",
    "\n",
    "list = [\"Rhea\",\"RAST\", \"DRAM_KO\", \"DRAM_EC\", \"Prokka\"]\n",
    "for current in list:\n",
    "    mapping_records = []\n",
    "    count = 0\n",
    "    if current != \"RAST\":\n",
    "        continue\n",
    "    for term in tqdm(all_data[current]):\n",
    "        count += 1\n",
    "        #if count == 100:\n",
    "        #    break\n",
    "        if term == \"SSO:000009137\":\n",
    "            continue\n",
    "        rxn_candidates = {}\n",
    "        rxn_list = []\n",
    "        next_list = []\n",
    "        if \"msrxn\" in all_data[current][term]:\n",
    "            for msrxn in all_data[current][term][\"msrxn\"]:\n",
    "                if msrxn[0:6] == \"MSRXN:\":\n",
    "                    msrxn = msrxn[6:]\n",
    "                if msrxn not in rxn_candidates:\n",
    "                    rxn_candidates[msrxn] = {\"score\":0,\"hits\":{},\"genes\":{}}\n",
    "                rxn_candidates[msrxn][\"score\"] += 16\n",
    "                if \"D\" not in rxn_candidates[msrxn][\"hits\"]:\n",
    "                    rxn_candidates[msrxn][\"hits\"][\"D\"] = 0\n",
    "                rxn_candidates[msrxn][\"hits\"][\"D\"] += 1\n",
    "                if msrxn not in rxn_list:\n",
    "                    rxn_list.append(msrxn)\n",
    "                if msrxn in rxn_ec:\n",
    "                    for ec in rxn_ec[msrxn]:\n",
    "                        if \"MS\" in ec_hash[ec]:\n",
    "                            for msrxn in ec_hash[ec][\"MS\"]:\n",
    "                                if msrxn[0:6] == \"MSRXN:\":\n",
    "                                    msrxn = msrxn[6:]\n",
    "                                if msrxn not in rxn_candidates:\n",
    "                                    rxn_candidates[msrxn] = {\"score\":0,\"hits\":{},\"genes\":{}}\n",
    "                                rxn_candidates[msrxn][\"score\"] += 10\n",
    "                                if \"Re\" not in rxn_candidates[msrxn][\"hits\"]:\n",
    "                                    rxn_candidates[msrxn][\"hits\"][\"Re\"] = 0\n",
    "                                rxn_candidates[msrxn][\"hits\"][\"Re\"] += 1\n",
    "                                if msrxn not in next_list:\n",
    "                                    next_list.append(msrxn)\n",
    "        if \"ec\" in all_data[current][term]:\n",
    "            for ec in all_data[current][term][\"ec\"]:\n",
    "                if ec in ec_hash:\n",
    "                    if \"MS\" in ec_hash[ec]:\n",
    "                        for msrxn in ec_hash[ec][\"MS\"]:\n",
    "                            if msrxn[0:6] == \"MSRXN:\":\n",
    "                                msrxn = msrxn[6:]\n",
    "                            if msrxn not in rxn_candidates:\n",
    "                                rxn_candidates[msrxn] = {\"score\":0,\"hits\":{},\"genes\":{}}\n",
    "                            rxn_candidates[msrxn][\"score\"] += 12\n",
    "                            if \"E\" not in rxn_candidates[msrxn][\"hits\"]:\n",
    "                                rxn_candidates[msrxn][\"hits\"][\"E\"] = 0\n",
    "                            rxn_candidates[msrxn][\"hits\"][\"E\"] += 1\n",
    "                            if msrxn not in rxn_list:\n",
    "                                rxn_list.append(msrxn)\n",
    "        for rxn in next_list:\n",
    "            if rxn not in rxn_list:\n",
    "                rxn_list.append(rxn)\n",
    "        next_list = []\n",
    "        if \"genes\" in all_data[current][term]:\n",
    "            for gene in all_data[current][term][\"genes\"]:\n",
    "                if gene in annotations_by_gene:\n",
    "                    for anno in annotations_by_gene[gene]:\n",
    "                        if anno != current:\n",
    "                            for item in annotations_by_gene[gene][anno]:\n",
    "                                newterm = item[\"term\"]\n",
    "                                if newterm[0:5] == \"RHEA:\":\n",
    "                                    newterm = newterm[5:]\n",
    "                                if newterm in all_data[anno]:\n",
    "                                    for msrxn in all_data[anno][newterm][\"msrxn\"]:\n",
    "                                        if msrxn[0:6] == \"MSRXN:\":\n",
    "                                            msrxn = msrxn[6:]\n",
    "                                        if msrxn not in rxn_candidates:\n",
    "                                            rxn_candidates[msrxn] = {\"score\":0,\"hits\":{},\"genes\":{}}\n",
    "                                        ec_match = False\n",
    "                                        if \"ec\" in all_data[current][term] and \"ec\" in all_data[anno][newterm]:\n",
    "                                            for ec in all_data[current][term][\"ec\"]:\n",
    "                                                if ec in all_data[anno][newterm][\"ec\"]:\n",
    "                                                    ec_match = True\n",
    "                                                    break\n",
    "                                        if ec_match:\n",
    "                                            rxn_candidates[msrxn][\"score\"] += 12\n",
    "                                            if \"Gd\" not in rxn_candidates[msrxn][\"hits\"]:\n",
    "                                                rxn_candidates[msrxn][\"hits\"][\"Gd\"] = {}\n",
    "                                            if anno+\"|\"+newterm not in rxn_candidates[msrxn][\"hits\"][\"Gd\"]:\n",
    "                                                rxn_candidates[msrxn][\"hits\"][\"Gd\"][anno+\"|\"+newterm] = 0\n",
    "                                            rxn_candidates[msrxn][\"hits\"][\"Gd\"][anno+\"|\"+newterm] += 1\n",
    "                                        else:\n",
    "                                            rxn_candidates[msrxn][\"score\"] += 3\n",
    "                                            if \"Gnd\" not in rxn_candidates[msrxn][\"hits\"]:\n",
    "                                                rxn_candidates[msrxn][\"hits\"][\"Gnd\"] = {}\n",
    "                                            if anno+\"|\"+newterm not in rxn_candidates[msrxn][\"hits\"][\"Gnd\"]:\n",
    "                                                rxn_candidates[msrxn][\"hits\"][\"Gnd\"][anno+\"|\"+newterm] = 0\n",
    "                                            rxn_candidates[msrxn][\"hits\"][\"Gnd\"][anno+\"|\"+newterm] += 1\n",
    "                                        if msrxn not in rxn_list:\n",
    "                                            rxn_list.append(msrxn)\n",
    "                                        if msrxn in rxn_ec:\n",
    "                                            for ec in rxn_ec[msrxn]:\n",
    "                                                if \"MS\" in ec_hash[ec]:\n",
    "                                                    for msrxn in ec_hash[ec][\"MS\"]:\n",
    "                                                        if msrxn[0:6] == \"MSRXN:\":\n",
    "                                                            msrxn = msrxn[6:]\n",
    "                                                        if msrxn not in rxn_candidates:\n",
    "                                                            rxn_candidates[msrxn] = {\"score\":0,\"hits\":{},\"genes\":{}}\n",
    "                                                        if ec in all_data[current][term][\"ec\"]:\n",
    "                                                            rxn_candidates[msrxn][\"score\"] += 8\n",
    "                                                            if \"Gre\" not in rxn_candidates[msrxn][\"hits\"]:\n",
    "                                                                rxn_candidates[msrxn][\"hits\"][\"Gre\"] = {}\n",
    "                                                            if anno+\"|\"+newterm not in rxn_candidates[msrxn][\"hits\"][\"Gre\"]:\n",
    "                                                                rxn_candidates[msrxn][\"hits\"][\"Gre\"][anno+\"|\"+newterm] = 0\n",
    "                                                            rxn_candidates[msrxn][\"hits\"][\"Gre\"][anno+\"|\"+newterm] += 1\n",
    "                                                        else:\n",
    "                                                            rxn_candidates[msrxn][\"score\"] += 1\n",
    "                                                            if \"Gnre\" not in rxn_candidates[msrxn][\"hits\"]:\n",
    "                                                                rxn_candidates[msrxn][\"hits\"][\"Gnre\"] = {}\n",
    "                                                            if anno+\"|\"+newterm not in rxn_candidates[msrxn][\"hits\"][\"Gnre\"]:\n",
    "                                                                rxn_candidates[msrxn][\"hits\"][\"Gnre\"][anno+\"|\"+newterm] = 0\n",
    "                                                            rxn_candidates[msrxn][\"hits\"][\"Gnre\"][anno+\"|\"+newterm] += 1\n",
    "                                                        if msrxn not in next_list:\n",
    "                                                            next_list.append(msrxn)\n",
    "                                if \"ec\" in all_data[anno][newterm]:\n",
    "                                    for ec in all_data[anno][newterm][\"ec\"]:\n",
    "                                        if ec in ec_hash:\n",
    "                                            if \"MS\" in ec_hash[ec]:\n",
    "                                                for msrxn in ec_hash[ec][\"MS\"]:\n",
    "                                                    if msrxn[0:6] == \"MSRXN:\":\n",
    "                                                        msrxn = msrxn[6:]\n",
    "                                                    if msrxn not in rxn_candidates:\n",
    "                                                        rxn_candidates[msrxn] = {\"score\":0,\"hits\":{},\"genes\":{}}\n",
    "                                                    if ec in all_data[current][term][\"ec\"]:\n",
    "                                                        rxn_candidates[msrxn][\"score\"] += 10\n",
    "                                                        if \"Ge\" not in rxn_candidates[msrxn][\"hits\"]:\n",
    "                                                            rxn_candidates[msrxn][\"hits\"][\"Ge\"] = {}\n",
    "                                                        if newterm not in rxn_candidates[msrxn][\"hits\"][\"Ge\"]:\n",
    "                                                            rxn_candidates[msrxn][\"hits\"][\"Ge\"][anno+\"|\"+newterm] = 0\n",
    "                                                        rxn_candidates[msrxn][\"hits\"][\"Ge\"][anno+\"|\"+newterm] += 1\n",
    "                                                    else:\n",
    "                                                        rxn_candidates[msrxn][\"score\"] += 2\n",
    "                                                        if \"Gne\" not in rxn_candidates[msrxn][\"hits\"]:\n",
    "                                                            rxn_candidates[msrxn][\"hits\"][\"Gne\"] = {}\n",
    "                                                        if newterm not in rxn_candidates[msrxn][\"hits\"][\"Gne\"]:\n",
    "                                                            rxn_candidates[msrxn][\"hits\"][\"Gne\"][anno+\"|\"+newterm] = 0\n",
    "                                                        rxn_candidates[msrxn][\"hits\"][\"Gne\"][anno+\"|\"+newterm] += 1\n",
    "                                                    if msrxn not in rxn_list:\n",
    "                                                        rxn_list.append(msrxn)\n",
    "        for rxn in next_list:\n",
    "            if rxn not in rxn_list:\n",
    "                rxn_list.append(rxn)\n",
    "        for msrxn in rxn_list:\n",
    "            if msrxn in biochem.reactions and biochem.reactions.get_by_id(msrxn).is_obsolete:\n",
    "                continue\n",
    "            record = {\"Term\":term,\"Name\":None,\"EC\":None,\"Genes\":None,\"Gene count\":0,\"MSRXN\":msrxn,\"MSEC\":None,\"MSName\":None,\"Equation\":None,\"Score\":rxn_candidates[msrxn][\"score\"],\"Rhea\":\"\",\"RAST\":\"\", \"DRAM_KO\":\"\", \"DRAM_EC\":\"\", \"Prokka\":\"\",\"Rhea-M\":\"\",\"RAST-M\":\"\", \"DRAM_KO-M\":\"\", \"DRAM_EC-M\":\"\", \"Prokka-M\":\"\"}\n",
    "            evidence_list = [\"D\",\"E\",\"Re\",\"Gd\",\"Ge\",\"Gre\",\"Gnd\",\"Gne\",\"Gnre\"]\n",
    "            if \"D\" in rxn_candidates[msrxn][\"hits\"]:\n",
    "                record[current+\"-M\"] = 1\n",
    "            termhash = {}\n",
    "            for evidence in evidence_list:\n",
    "                if evidence[0:1] != \"G\" and evidence in rxn_candidates[msrxn][\"hits\"]:\n",
    "                    record[current] += evidence+str(rxn_candidates[msrxn][\"hits\"][evidence])\n",
    "                if evidence[0:1] == \"G\" and evidence in rxn_candidates[msrxn][\"hits\"]:\n",
    "                    for iterm in rxn_candidates[msrxn][\"hits\"][evidence]:\n",
    "                        if iterm not in termhash:\n",
    "                            termhash[iterm] = {}\n",
    "                        if evidence not in termhash[iterm]:\n",
    "                            termhash[iterm][evidence] = 0\n",
    "                        termhash[iterm][evidence] += 1\n",
    "            for fullterm in termhash:\n",
    "                (anno,iterm) = fullterm.split(\"|\")\n",
    "                if record[anno] != \"\":\n",
    "                    record[anno] += \"/\"\n",
    "                line = iterm+\":\"\n",
    "                for evidence in termhash[fullterm]:\n",
    "                    if \"Gd\" == evidence or \"Gnd\" == evidence:\n",
    "                        record[anno+\"-M\"] = 1\n",
    "                    if line != iterm+\":\":\n",
    "                        line += \";\"\n",
    "                    line += evidence+str(termhash[fullterm][evidence])\n",
    "                record[anno] += line\n",
    "            if \"genes\" in all_data[current][term]:\n",
    "                record[\"Gene count\"] = len(all_data[current][term][\"genes\"])\n",
    "                record[\"Genes\"] = \", \".join(all_data[current][term][\"genes\"])\n",
    "            if \"name\" in all_data[current][term] and all_data[current][term][\"name\"]:\n",
    "                record[\"Name\"] = all_data[current][term][\"name\"]\n",
    "            if \"ec\" in all_data[current][term]:\n",
    "                newlist = []\n",
    "                for ec in all_data[current][term][\"ec\"]:\n",
    "                    ec = trans_ec(ec)\n",
    "                    if ec not in newlist:\n",
    "                        newlist.append(ec)\n",
    "                record[\"EC\"] = \", \".join(newlist)\n",
    "            if msrxn in rxn_ec:\n",
    "                newlist = []\n",
    "                currec = rxn_ec[msrxn].keys()\n",
    "                for ec in currec:\n",
    "                    ec = trans_ec(ec)\n",
    "                    if ec not in newlist:\n",
    "                        newlist.append(ec)\n",
    "                record[\"MSEC\"] = \", \".join(newlist)\n",
    "            current_ms = get_ms_data(msrxn)\n",
    "            if \"name\" in current_ms and current_ms[\"name\"]:\n",
    "                record[\"MSName\"] = current_ms[\"name\"]\n",
    "            if \"equation\" in current_ms and current_ms[\"equation\"]:\n",
    "                record[\"Equation\"] = current_ms[\"equation\"]\n",
    "            if record[\"Gene count\"] > 0:\n",
    "                mapping_records.append(record)\n",
    "    df = pd.DataFrame.from_records(mapping_records)\n",
    "    df.to_csv(kbdevutil.out_dir()+current+\"_mappings.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the annotation ontology API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbdevutil = KBDevUtils(\"Ontology\",ws_version=\"appdev\")\n",
    "appdev_annoapi = kbdevutil.anno_client(native_python_api=True)\n",
    "with open('debug.json') as json_file:\n",
    "    input_data = json.load(json_file)\n",
    "output = anno_api.add_annotation_ontology_events(input_data)\n",
    "output = anno_api.get_annotation_ontology_events({\n",
    "    \"input_ref\" : \"102004/Methanosarcina_acetivorans_C2A_DRAM_RAST\"\n",
    "#    \"input_ref\" : \"93487/Ruepo_2orMoreRKM\"\n",
    "#    \"input_ref\" : \"77537/Sco_RAST_Prokka_BlastKOALA_PTools_DeepEC_DeepGO\"\n",
    "#    \"input_ref\" : \"77537/Sco_Union_BestUnion_2plus_Best2plus_RASTKEGG\"\n",
    "#    \"input_ref\" : \"77925/Pf5.6\"#,\n",
    "#    \"input_workspace\" : \n",
    "})\n",
    "with open('output.json', 'w') as outfile:\n",
    "    json.dump(output, outfile, indent=2)\n",
    "\n",
    "terms = ontology[\"events\"][0][\"ontology_terms\"]\n",
    "ontology[\"events\"][0][\"ontology_id\"] = \"SEED\"\n",
    "for gene in terms:\n",
    "    terms[gene][0][\"evidence\"] = \"test\"\n",
    "    terms[gene][0][\"term\"] = terms[gene][0][\"term\"].split(\":\")[1]\n",
    "    \n",
    "output = anno_api.add_annotation_ontology_events({\n",
    "    \"input_ref\" : \"GCF_000012265.1\",\n",
    "    \"input_workspace\" : 77925,\n",
    "    \"output_name\" : \"TestOntologyOutput\",\n",
    "    \"events\" : ontology[\"events\"],\n",
    "    \"output_workspace\": \"kimbrel1:narrative_1606152384556\",\n",
    "    \"save\" : 1\n",
    "})\n",
    "\n",
    "ontology = anno_api.get_annotation_ontology_events({\n",
    "    \"input_ref\" : \"TestOntologyOutput\",\n",
    "    \"input_workspace\" : \"kimbrel1:narrative_1606152384556\"\n",
    "})\n",
    "\n",
    "with open('/Users/chenry/output.json', 'w') as outfile:\n",
    "    json.dump(ontology, outfile, indent=2)\n",
    "\n",
    "#Escherichia_coli_K-12_MG1655\n",
    "#Synechocystis_PCC_6803\n",
    "#Methanosarcina_barkeri_Fusaro\n",
    "#Clostridium_beijerinckii_NCIMB_8052\n",
    "#Streptomyces_coelicolor_A3_2\n",
    "\n",
    "ontology_input = {\n",
    "    \"input_ref\":\"Streptomyces_coelicolor_A3_2\",\n",
    "    \"input_workspace\":\"chenry:narrative_1612295985064\",\n",
    "    \"output_name\":\"test\",\n",
    "    \"output_workspace\":\"chenry:narrative_1612295985064\",\n",
    "    \"clear_existing\":0,\n",
    "    \"overwrite_matching\":1,\n",
    "    \"save\":1,\n",
    "    \"events\":[\n",
    "        {\n",
    "            \"event_id\": \"annotate_genome:1.8.1:SSO:2020-11-23T17:51:18\",\n",
    "            \"original_description\": \"annotate_genome:2020-11-23T17:51:18:2020-11-23T17:51:18\",\n",
    "            \"description\": \"annotate_genome:2020-11-23T17:51:18:2020-11-23T17:51:18:2020-11-23T17:51:18\",\n",
    "            \"ontology_id\": \"SSO\",\n",
    "            \"method\": \"annotate_genome\",\n",
    "            \"method_version\": \"1.8.1\",\n",
    "            \"timestamp\": \"2020-11-23T17:51:18\",\n",
    "            \"ontology_terms\":{\"sgl0001\": [{\"term\": \"SSO:000001563\"}]}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "#with open('/Users/chenry/ontology_api_input.json') as json_file:\n",
    "#    ontology_input = json.load(json_file)\n",
    "#print(\"Loading ontology terms to genome!\")\n",
    "output = anno_api.add_annotation_ontology_events(ontology_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Published Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import cobra\n",
    "import cobrakbase\n",
    "kbase_api = cobrakbase.KBaseAPI()\n",
    "\n",
    "genome_list = [\"Sco\",\"Eco\",\"Cbe\",\"Mba\"]\n",
    "pub_model_hash = {\n",
    "    \"Sco\" : \"iMK1208\",\n",
    "    \"Eco\" : \"iML1515.kb\",\n",
    "    \"Cbe\" : \"iCM925_GF\",\n",
    "    \"Mba\" : \"iMG746_GF\"\n",
    "}\n",
    "pub_fba_hash = {\n",
    "    \"Sco\" : \"iMK1208_FBA\",\n",
    "    \"Eco\" : \"iML1515.kb_FBA\",\n",
    "    \"Cbe\" : \"iCM925_FBA\",\n",
    "    \"Mba\" : \"iMG746_FBA\"\n",
    "}\n",
    "pub_pheno_hash = {\n",
    "    \"Sco\" : \"iMK1208_Pheno\",\n",
    "    \"Eco\" : \"iML1515.kb_Pheno\",\n",
    "    \"Cbe\" : \"iCM925_Pheno\",\n",
    "    \"Mba\" : \"iMG746_Pheno\"\n",
    "}\n",
    "stats = {\n",
    "    \"Sco\":{},\"Eco\":{},\"Cbe\":{},\"Mba\":{}\n",
    "}\n",
    "types = [\"Best\",\"Union\",\"RAST\",\"Published\"]\n",
    "entities = [\"gene\",\"reaction\",\"pospheno\"]\n",
    "print(\"Species\\tType\\tReactions\\tGenes\\tGapfilled\\tBlocked\\tPospheno\\tGene match\\tReaction match\\tPheno match\")\n",
    "for genome in genome_list:\n",
    "    #Get:gene associated reactions;genes;gapfilled\n",
    "    models = [genome+\"_Best\",genome+\"_Union\",genome+\"_StdRAST_Mdl\",pub_model_hash[genome]]\n",
    "    count = 0\n",
    "    for model in models:\n",
    "        current_object = kbase_api.get_object(model,\"patrikd:narrative_1605639637696\")\n",
    "        stats[genome][types[count]] = {\n",
    "            \"reactions\":0,\n",
    "            \"gapfilled\":0,\n",
    "            \"blocked\":0,\n",
    "            \"genes\":0,\n",
    "            \"gene_hash\":{},\n",
    "            \"reaction_hash\":{},\n",
    "            \"pospheno\":0,\n",
    "            \"pospheno_hash\":{},\n",
    "            \"match_reaction\":0,\n",
    "            \"match_gene\":0,\n",
    "            \"match_pospheno\":0\n",
    "        }\n",
    "        for rxn in current_object[\"modelreactions\"]:\n",
    "            rxn[\"id\"] = rxn[\"id\"].replace(\"_z0\",\"_c0\")\n",
    "            if \"gapfill_data\" in rxn and len(rxn[\"gapfill_data\"]) > 0:\n",
    "                stats[genome][types[count]][\"gapfilled\"] += 1\n",
    "            elif count == 3 and len(rxn[\"modelReactionProteins\"]) == 0:\n",
    "                stats[genome][types[count]][\"gapfilled\"] += 1\n",
    "            if len(rxn[\"modelReactionProteins\"]) > 0:\n",
    "                stats[genome][types[count]][\"reactions\"] += 1\n",
    "                stats[genome][types[count]][\"reaction_hash\"][rxn[\"id\"]] = 1\n",
    "                for prot in rxn[\"modelReactionProteins\"]:\n",
    "                    for subunit in prot[\"modelReactionProteinSubunits\"]:\n",
    "                        for ftr in subunit[\"feature_refs\"]:\n",
    "                            ftr = ftr.split(\"/\").pop()\n",
    "                            stats[genome][types[count]][\"gene_hash\"][ftr] = 1             \n",
    "        stats[genome][types[count]][\"genes\"] = len(stats[genome][types[count]][\"gene_hash\"])\n",
    "        count += 1\n",
    "    \n",
    "    #Get:blocked\n",
    "    models = [genome+\"_Best_FBA\",genome+\"_Union_FBA\",genome+\"_StdRAST_FBA\",pub_fba_hash[genome]]\n",
    "    count = 0\n",
    "    for model in models:\n",
    "        current_object = kbase_api.get_object(model,\"patrikd:narrative_1605639637696\")\n",
    "        for var in current_object[\"FBAReactionVariables\"]:\n",
    "            if var[\"class\"] == \"Blocked\":\n",
    "                stats[genome][types[count]][\"blocked\"] += 1\n",
    "        count += 1\n",
    "    #Get:Neg;Pos\n",
    "    models = [genome+\"_Best_Pheno\",genome+\"_Union_Pheno\",genome+\"_StdRAST_Pheno\",pub_pheno_hash[genome]]\n",
    "    count = 0\n",
    "    for model in models:\n",
    "        if not (count == 3 and genome == \"Sco\"):\n",
    "            current_object = kbase_api.get_object(model,\"patrikd:narrative_1605639637696\")\n",
    "            for pheno in current_object[\"phenotypeSimulations\"]:\n",
    "                if pheno[\"simulatedGrowth\"] > 0:\n",
    "                    stats[genome][types[count]][\"pospheno_hash\"][pheno[\"id\"]] = 1\n",
    "                    stats[genome][types[count]][\"pospheno\"] += 1\n",
    "        count += 1   \n",
    "    #Computing matches\n",
    "    for entity in entities:\n",
    "        for count in range(0,3):\n",
    "            for entid in stats[genome][\"Published\"][entity+\"_hash\"]:\n",
    "                if entid in stats[genome][types[count]][entity+\"_hash\"]:\n",
    "                    stats[genome][types[count]][\"match_\"+entity] += 1\n",
    "    #Printing results\n",
    "    for currtype in types:\n",
    "        d = stats[genome][currtype]\n",
    "        print(genome+\"\\t\"+currtype+\"\\t\"+str(d[\"reactions\"])+\"\\t\"+str(d[\"genes\"])+\"\\t\"+str(d[\"gapfilled\"])\\\n",
    "            +\"\\t\"+str(d[\"blocked\"])+\"\\t\"+str(d[\"pospheno\"])+\"\\t\"+str(d[\"match_gene\"])+\"\\t\"+str(d[\"match_reaction\"])+\"\\t\"+str(d[\"match_pospheno\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Ontology API Against Gold Standard Genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import cobra\n",
    "import cobrakbase\n",
    "sys.path.append(\"/Users/chenry/code/MetabolicModelGapfilling/lib/\")\n",
    "#sys.path.append(\"/Users/chenry/code/annotation_ontology_api/lib\")\n",
    "from annotation_ontology_api.annotation_ontology_apiServiceClient import annotation_ontology_api\n",
    "#from annotation_ontology_api.annotation_ontology_api import AnnotationOntologyAPI\n",
    "\n",
    "#Test for ontology API\n",
    "kbase_api = cobrakbase.KBaseAPI()\n",
    "#anno_api = AnnotationOntologyAPI({\"data_directory\" : \"/Users/chenry/code/annotation_ontology_api/data/\"},kbase_api.ws_client,None)\n",
    "anno_api = annotation_ontology_api()\n",
    "genome_list = [\"Ani_RAST\"]\n",
    "#genome_list = [\"Sco_RAST\",\"Eco_RAST\",\"Cbe_RAST\",\"Syn_RAST\",\"Mba_RAST\"]\n",
    "genome_hash = {\n",
    "    \"Eco_RAST\": \"Eco_RAST_Prokka\",\n",
    "    \"Cbe_RAST\": \"Cbe_RAST_Prokka\",\n",
    "    \"Syn_RAST\": \"Syn_RAST_Prokka\",\n",
    "    \"Mba_RAST\": \"Mba_RAST_Prokka\",\n",
    "    \"Sco_RAST\": \"Sco_RAST_Prokka_BlastKOALA_PTools_DeepEC_DeepGO\",\n",
    "    \"Ani_RAST\": \"Ani_RAST_Prokka\"\n",
    "}\n",
    "for genome in genome_list:\n",
    "    print(genome)\n",
    "    ontology_output = anno_api.get_annotation_ontology_events({\n",
    "        \"input_ref\" : \"patrikd:narrative_1605639637696/\"+genome,\n",
    "    })\n",
    "    genome_object = kbase_api.get_object(genome,\"patrikd:narrative_1605639637696\")\n",
    "    ontology_input = {\n",
    "        \"input_ref\":genome_hash[genome],\n",
    "        \"input_workspace\":\"patrikd:narrative_1605639637696\",\n",
    "        \"output_name\":genome_hash[genome],\n",
    "        \"output_workspace\":\"patrikd:narrative_1605639637696\",        \n",
    "        \"save\":1,\n",
    "#        \"type\":\"KBaseGenomes.Genome\",\n",
    "#        \"object\":genome,\n",
    "        \"clear_existing\":0,\n",
    "        \"overwrite_matching\":1,\n",
    "        \"events\":[]\n",
    "    }\n",
    "    for event in ontology_output[\"events\"]:\n",
    "        print(event[\"ontology_id\"])\n",
    "        if event[\"ontology_id\"] == \"SSO\":\n",
    "            ontology_input[\"events\"].append(event)\n",
    "            break\n",
    "    \n",
    "    with open('/Users/chenry/output.json', 'w') as outfile:\n",
    "        json.dump(ontology_output, outfile, indent=2)\n",
    "    \n",
    "    if len(ontology_input[\"events\"]) == 1:\n",
    "        print(str(len(ontology_input[\"events\"])))\n",
    "        print(ontology_input[\"events\"][0][\"ontology_id\"])\n",
    "        ontology_output[\"events\"][0][\"method\"] = \"RAST annotation\"\n",
    "        ontology_output[\"events\"][0][\"description\"] = \"RAST annotation:\"+ontology_output[\"events\"][0][\"ontology_id\"]+\":\"+ontology_output[\"events\"][0][\"timestamp\"]    \n",
    "        ontology_output[\"events\"][0][\"ontology_terms\"] = {}\n",
    "        for ftr in genome_object[\"features\"]:\n",
    "            if \"functions\" in ftr:\n",
    "                for func in ftr[\"functions\"]:\n",
    "                    if ftr[\"id\"] not in ontology_input[\"events\"][0][\"ontology_terms\"]:\n",
    "                        ontology_input[\"events\"][0][\"ontology_terms\"][ftr[\"id\"]] = []\n",
    "                    ontology_input[\"events\"][0][\"ontology_terms\"][ftr[\"id\"]].append({\n",
    "                        \"term\": \"SSO:\"+func\n",
    "                    })\n",
    "        for ftr in genome_object[\"cdss\"]:\n",
    "            if \"functions\" in ftr:\n",
    "                for func in ftr[\"functions\"]:\n",
    "                    if ftr[\"id\"] not in ontology_input[\"events\"][0][\"ontology_terms\"]:\n",
    "                        ontology_input[\"events\"][0][\"ontology_terms\"][ftr[\"id\"]] = []\n",
    "                    ontology_input[\"events\"][0][\"ontology_terms\"][ftr[\"id\"]].append({\n",
    "                        \"term\": \"SSO:\"+func\n",
    "                    })\n",
    "        ontology_output = anno_api.add_annotation_ontology_events(ontology_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing SSO reactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing Super Annotated E. coli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/chenry/code/cb_annotation_ontology_api/lib\")\n",
    "import os\n",
    "import cobra\n",
    "import cobrakbase\n",
    "import json\n",
    "import csv\n",
    "import logging\n",
    "import cplex\n",
    "import optlang\n",
    "import re\n",
    "import pandas as pd\n",
    "from optlang.symbolics import Zero, add\n",
    "import cobra.util.solver as sutil\n",
    "from cobrakbase.core.converters import KBaseFBAModelToCobraBuilder\n",
    "from cobrakbase.Workspace.WorkspaceClient import Workspace as WorkspaceClient\n",
    "from annotation_ontology_api.annotation_ontology_api import AnnotationOntologyAPI\n",
    "from cobra.core.dictlist import DictList\n",
    "from cobra.core import Gene, Metabolite, Model, Reaction\n",
    "from IPython.core.display import HTML\n",
    "#Test for ontology API\n",
    "kbase_api = cobrakbase.KBaseAPI()\n",
    "anno_api = AnnotationOntologyAPI({\"data_directory\" : \"/Users/chenry/code/cb_annotation_ontology_api/data/\"},\n",
    "    kbase_api.ws_client,None)\n",
    "\n",
    "output = anno_api.get_annotation_ontology_events({\n",
    "    \"input_ref\" : \"Eco_Union_BestUnion_2plus_Best2plus_RASTKEGG.pdb\",\n",
    "    \"input_workspace\" : 133085\n",
    "})\n",
    "with open('EcoliSuperAnnotation', 'w') as outfile:\n",
    "    json.dump(output, outfile, indent=2)\n",
    "#Print annotations in tabular form\n",
    "annotations = {}\n",
    "for event in output[\"events\"]:\n",
    "    name = None\n",
    "    if event[\"original_description\"][0:4] == \"RAST\":\n",
    "        name = \"RAST\"\n",
    "    elif event[\"original_description\"][0:6] == \"Prokka\":\n",
    "        name = \"Prokka\"\n",
    "    elif event[\"original_description\"][0:5] == \"Blast\":\n",
    "        name = \"Koala\"\n",
    "    elif event[\"original_description\"][0:7] == \"Pathway\":\n",
    "        name = \"PathwayTools\"\n",
    "    elif event[\"original_description\"][0:6] == \"DeepEC\":\n",
    "        name = \"DeepEC\"\n",
    "    elif event[\"original_description\"][0:6] == \"DeepGO\":\n",
    "        name = \"DeepGO\"\n",
    "    elif event[\"original_description\"][0:3] == \"KBA\":\n",
    "        name = \"PDB\"\n",
    "    if name:\n",
    "        for gene in event[\"ontology_terms\"]:\n",
    "            for item in event[\"ontology_terms\"][gene]:\n",
    "                if \"modelseed_ids\" in item:\n",
    "                    if gene not in annotations:\n",
    "                        annotations[gene] = {}\n",
    "                    for msid in item[\"modelseed_ids\"]:\n",
    "                        if msid not in annotations[gene]:\n",
    "                            annotations[gene][msid] = {}\n",
    "                        if name not in annotations[gene][msid]:\n",
    "                            annotations[gene][msid][name] = []\n",
    "                        if item[\"term\"] not in annotations[gene][msid][name]:\n",
    "                            annotations[gene][msid][name].append(item[\"term\"])\n",
    "#Loading and saving dataframe\n",
    "annos = [\"RAST\",\"Prokka\",\"Koala\",\"PathwayTools\",\"DeepEC\",\"DeepGO\",\"PDB\"]\n",
    "data = {\"Gene\":[],\"Reactions\":[],\"RAST\":[],\"Prokka\":[],\"Koala\":[],\"PathwayTools\":[],\"DeepEC\":[],\"DeepGO\":[],\"PDB\":[]}\n",
    "for gene in annotations:\n",
    "    for rxn in annotations[gene]:\n",
    "        data[\"Gene\"].append(gene)\n",
    "        data[\"Reactions\"].append(rxn)\n",
    "        for anno in annos:\n",
    "            if anno in annotations[gene][rxn]:\n",
    "                data[anno].append(\",\".join(annotations[gene][rxn][anno]))\n",
    "            else:\n",
    "                data[anno].append(None)\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"EcoliSuperAnnotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'anno_api' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/chenry/code/ProjectNotebooks/TemplateFunctions/OntologyFunctions.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chenry/code/ProjectNotebooks/TemplateFunctions/OntologyFunctions.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ontology \u001b[39m=\u001b[39m anno_api\u001b[39m.\u001b[39mget_annotation_ontology_events({\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenry/code/ProjectNotebooks/TemplateFunctions/OntologyFunctions.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_ref\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39m\"\u001b[39m\u001b[39mPf5.6\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenry/code/ProjectNotebooks/TemplateFunctions/OntologyFunctions.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_workspace\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39m77925\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenry/code/ProjectNotebooks/TemplateFunctions/OntologyFunctions.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m })\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenry/code/ProjectNotebooks/TemplateFunctions/OntologyFunctions.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m/Users/chenry/translation.json\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m outfile:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenry/code/ProjectNotebooks/TemplateFunctions/OntologyFunctions.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     json\u001b[39m.\u001b[39mdump(anno_api\u001b[39m.\u001b[39malias_hash, outfile, indent\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'anno_api' is not defined"
     ]
    }
   ],
   "source": [
    "ontology = anno_api.get_annotation_ontology_events({\n",
    "    \"input_ref\" : \"Pf5.6\",\n",
    "    \"input_workspace\" : 77925\n",
    "})\n",
    "with open('/Users/chenry/translation.json', 'w') as outfile:\n",
    "    json.dump(anno_api.alias_hash, outfile, indent=2)\n",
    "with open('/Users/chenry/output.json', 'w') as outfile:\n",
    "    json.dump(ontology, outfile, indent=2)\n",
    "\n",
    "terms = ontology[\"events\"][0][\"ontology_terms\"]\n",
    "ontology[\"events\"][0][\"ontology_id\"] = \"SEED\"\n",
    "for gene in terms:\n",
    "    terms[gene][0][\"evidence\"] = \"test\"\n",
    "    terms[gene][0][\"term\"] = terms[gene][0][\"term\"].split(\":\")[1]\n",
    "    \n",
    "with open('/Users/chenry/output2.json', 'w') as outfile:\n",
    "    json.dump(ontology, outfile, indent=2)\n",
    "    \n",
    "output = anno_api.add_annotation_ontology_events({\n",
    "    \"input_ref\" : \"GCF_000012265.1\",\n",
    "    \"input_workspace\" : 77925,\n",
    "    \"output_name\" : \"TestOntologyOutput\",\n",
    "    \"events\" : ontology[\"events\"],\n",
    "    \"output_workspace\": \"kimbrel1:narrative_1606152384556\",\n",
    "    \"save\" : 1\n",
    "})\n",
    "\n",
    "#with open('/Users/chenry/genome.json', 'w') as outfile:\n",
    "#    json.dump(output[\"object\"], outfile, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not sure what this code is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sso_hash = dict()\n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/genome_sso.json') as json_file:\n",
    "    sso_hash = json.load(json_file)\n",
    "\n",
    "sso_template = dict()\n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/SSO_reactions.json') as json_file:\n",
    "    sso_template = json.load(json_file)\n",
    "\n",
    "reaction_hash = dict()\n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/genome_reactions.json') as json_file:\n",
    "    reaction_hash = json.load(json_file)\n",
    "\n",
    "function_hash = dict()\n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/genome_functions.json') as json_file:\n",
    "    function_hash = json.load(json_file)\n",
    "\n",
    "functions = dict()\n",
    "comparison = dict()\n",
    "for genome in sso_hash:\n",
    "    if genome in reaction_hash:\n",
    "        sso_based_reactions = dict()\n",
    "        sso_based_genes = dict()\n",
    "        for gene in sso_hash[genome]:\n",
    "            for sso in sso_hash[genome][gene]:\n",
    "                if sso in sso_template:\n",
    "                    for reaction in sso_template[sso]:\n",
    "                        if reaction not in sso_based_reactions:\n",
    "                            sso_based_reactions[reaction] = dict()\n",
    "                        sso_based_reactions[reaction][gene] = 1\n",
    "                        if gene not in sso_based_genes:\n",
    "                            sso_based_genes[gene] = dict()\n",
    "                        sso_based_genes[gene][reaction] = 1\n",
    "        comparison[genome] = {\n",
    "            \"SSO_reactions\": len(sso_based_reactions),\n",
    "            \"SSO_genes\": len(sso_based_genes),\n",
    "            \"Extra_SS_reactions\": [],\n",
    "            \"Extra_SS_genes\": [],\n",
    "            \"Extra_MS_reactions\": [],\n",
    "            \"Extra_MS_genes\": [],\n",
    "            \"Extra_SS_reactions_counts\": 0,\n",
    "            \"Extra_SS_genes_counts\": 0,\n",
    "            \"Extra_MS_reactions_counts\": 0,\n",
    "            \"Extra_MS_genes_counts\": 0,\n",
    "            \"MS_reactions\": len(reaction_hash[genome]),\n",
    "            \"MS_genes\" 0,\n",
    "        }\n",
    "        ms_based_genes = dict()\n",
    "        for reaction in reaction_hash[genome]:\n",
    "            if reaction not in sso_based_reactions:\n",
    "                comparison[genome][\"Extra_MS_reactions\"].append(reaction)\n",
    "                comparison[genome][\"Extra_MS_reactions_counts\"] += 1\n",
    "            for gene in reaction_hash[genome][reaction]:\n",
    "                if gene not in ms_based_genes:\n",
    "                    ms_based_genes[gene] = dict()\n",
    "                ms_based_genes[gene][reaction] = 1\n",
    "        for reaction in sso_based_reactions:\n",
    "            if reaction not in reaction_hash[genome]:\n",
    "                comparison[genome][\"Extra_SS_reactions\"].append(reaction)\n",
    "                comparison[genome][\"Extra_SS_reactions_counts\"] += 1\n",
    "        comparison[genome][\"MS_genes\"] = len(ms_based_genes)\n",
    "        for gene in ms_based_genes:\n",
    "            if gene not in sso_based_genes:\n",
    "                comparison[genome][\"Extra_MS_genes\"].append(gene)\n",
    "                comparison[genome][\"Extra_MS_genes_counts\"] += 1\n",
    "        for gene in sso_based_genes:\n",
    "            if gene not in ms_based_genes:\n",
    "                comparison[genome][\"Extra_SS_genes\"].append(gene)\n",
    "                comparison[genome][\"Extra_SS_genes_counts\"] += 1\n",
    "            \n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/comparison.json', 'w') as outfile:\n",
    "    json.dump(comparison, outfile)\n",
    "    \n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/problem_functions.json', 'w') as outfile:\n",
    "    json.dump(functions, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing reaction gene associations from all models in workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = msrecon.kbase_api.list_objects(\"chenry:narrative_1581959452634\")\n",
    "reaction_hash = dict()\n",
    "count = 0\n",
    "for obj in objects:\n",
    "    if obj[1][-14:] == \".RAST.mdl.base\":\n",
    "        count += 1\n",
    "        genomeid = obj[1][0:-14]\n",
    "        reaction_hash[genomeid] = dict()\n",
    "        model = kbase.get_from_ws(obj[1],\"chenry:narrative_1581959452634\")\n",
    "        for rxn in model.reactions:\n",
    "            reaction_hash[genomeid][rxn.id.split(\"_\")[0]] = dict()\n",
    "            for prot in rxn.data[\"modelReactionProteins\"]:\n",
    "                for subunit in prot[\"modelReactionProteinSubunits\"]:\n",
    "                    for ftr in subunit[\"feature_refs\"]:\n",
    "                        ftrid = ftr.split(\"/\").pop()\n",
    "                        reaction_hash[genomeid][rxn.id.split(\"_\")[0]][ftrid] = 0\n",
    "\n",
    "with open(kbdevutil.out_dir()+\"genome_reactions.json\", 'w') as outfile:\n",
    "    json.dump(reaction_hash, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_ModelSEED",
   "language": "python",
   "name": "python3_modelseed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
