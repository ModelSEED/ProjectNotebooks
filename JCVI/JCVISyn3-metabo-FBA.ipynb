{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cobrakbase 0.2.7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cobra\n",
    "import cobrakbase\n",
    "import json\n",
    "import csv\n",
    "import logging\n",
    "import cplex\n",
    "import optlang\n",
    "import re\n",
    "from optlang.symbolics import Zero, add\n",
    "import cobra.util.solver as sutil\n",
    "from cobrakbase.core.converters import KBaseFBAModelToCobraBuilder\n",
    "from cobrakbase.Workspace.WorkspaceClient import Workspace as WorkspaceClient\n",
    "from cobrakbase.core.kbase_object_factory import KBaseObjectFactory\n",
    "from cobrakbase.core.fba_utilities import KBaseFBAUtilities\n",
    "from cobra.core.dictlist import DictList\n",
    "from cobra.core import Gene, Metabolite, Model, Reaction\n",
    "from IPython.core.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\n",
      "261\n",
      "1-done\n",
      "2-done\n",
      "3-done\n",
      "4-done\n",
      "6-done\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"workspace\": 29280,\n",
    "    \"fbamodel_id\" : 'MMSyn3',\n",
    "    \"fbamodel_workspace\" : 29280,\n",
    "\t\"media_id\" : \"Complete\",\n",
    "\t\"media_workspace\" : \"KBaseMedia\",\n",
    "\t\"target_reaction\" : \"bio1\",\n",
    "\t\"source_fbamodel_id\" : \"MMSyn3Expansion\",\n",
    "\t\"source_fbamodel_workspace\" : 29280,\n",
    "\t\"feature_ko_list\" : [],\n",
    "\t\"reaction_ko_list\" : [],\n",
    "\t\"blacklist\" : [],\n",
    "\t\"custom_bound_list\" : [],\n",
    "\t\"media_supplement_list\" : [],\n",
    "\t\"minimum_target_flux\" : 0.1,\n",
    "    \"max\" : 1,\n",
    "    \"default_uptake\" : 0,\n",
    "    \"default_excretion\" : 100,\n",
    "    \"add_modelseed_reactions\" : 1,\n",
    "    \"use_modelseed_peak_hits\": 1,\n",
    "    \"gapfilling_annotation_sources\" : []\n",
    "}\n",
    "kbase_api = cobrakbase.KBaseAPI()\n",
    "media = kbase_api.get_from_ws(\"ArgonneLBMedia\",\"KBaseMedia\")\n",
    "kbmodel = kbase_api.get_from_ws(params[\"fbamodel_id\"],params[\"fbamodel_workspace\"])\n",
    "sourcemodel = kbase_api.get_from_ws(params[\"source_fbamodel_id\"],params[\"source_fbamodel_workspace\"])\n",
    "builder = KBaseFBAModelToCobraBuilder(kbmodel)\n",
    "builder = builder.with_media(media)\n",
    "model = builder.build()\n",
    "\n",
    "model.solver = 'cplex'\n",
    "\n",
    "metabolomics = kbase_api.get_from_ws(\"JCVI_Syn3_metabolomics\",29280)\n",
    "#Matching metabolomics data up to the ModelSEED\n",
    "modelseed_hash = {}\n",
    "if  params[\"add_modelseed_reactions\"]*params[\"use_modelseed_peak_hits\"] == 1:\n",
    "    modelseed = cobrakbase.modelseed.from_local('/Users/chenry/code/ModelSEEDDatabase')\n",
    "    modelseed_hash = metabolomics.map_to_modelseed(modelseed,\"_c0\")\n",
    "print(len(modelseed_hash))\n",
    "\n",
    "#Saving the list of original reactions\n",
    "original_reactions = {}\n",
    "for reaction in model.reactions:\n",
    "    original_reactions[reaction.id] = 1\n",
    "original_metabolites = {}\n",
    "for metabolite in model.metabolites:\n",
    "    original_metabolites[metabolite.id] = 1\n",
    "\n",
    "#Building metabolite hash and printing for viz in escher\n",
    "metabolites_with_peaks = dict()\n",
    "for met in sourcemodel.modelcompounds:\n",
    "    if hasattr(met,'dblinks'):\n",
    "        if \"KBWS/29280/JCVI_Syn3_metabolomics\" in met.dblinks:\n",
    "            array = met.dblinks[\"KBWS/29280/JCVI_Syn3_metabolomics\"]\n",
    "            metabolites_with_peaks[met.id] = 1\n",
    "for peak in modelseed_hash:\n",
    "    for cpd in modelseed_hash[peak]:\n",
    "        metabolites_with_peaks[cpd] = 1\n",
    "#Printing metabolites in TSV format\n",
    "file = open(\"expanded_jcvi_metabolites.csv\",\"w\") \n",
    "file.write(\"metabolite,concentration\\n\")\n",
    "for compound in metabolites_with_peaks:\n",
    "    if compound in original_metabolites:\n",
    "        file.write(compound+\",1\\n\") \n",
    "    elif re.search('cpd', compound):\n",
    "        file.write(compound+\",10\\n\")\n",
    "    elif re.search('enzc', compound):\n",
    "        file.write(compound+\",100\\n\")\n",
    "    elif re.search('spontc', compound):\n",
    "        file.write(compound+\",100\\n\")    \n",
    "file.close()\n",
    "\n",
    "#Creating peak string from model\n",
    "peakstring = sourcemodel.build_peakstring(\"KBWS/29280/JCVI_Syn3_metabolomics\",modelseed_hash)\n",
    "\n",
    "utilities = KBaseFBAUtilities(model,kbmodel,kbase_api,media = None,\n",
    "                 default_uptake = 100,default_excretion = 100,blacklist = [])\n",
    "\n",
    "#Extending model for gapfilling\n",
    "utilities.default_uptake = 0\n",
    "penalties = utilities.build_model_extended_for_gapfilling(1,[sourcemodel],[],10)\n",
    "\n",
    "#Adding drain fluxes for co-reactants used by reaction rules\n",
    "coreactants = [\n",
    "    \"cpd01569\",\"cpd00203\",\"cpd00364\",\"cpd00071\",\"cpd00022\",\"cpd00196\",\"cpd00013\",\"cpd00051\",\"cpd00059\",\"cpd00132\",\"cpd00146\",\"cpd00011\",\"cpd00010\",\"cpd01160\",\"cpd00084\",\"cpd00335\",\"cpd00055\",\"cpd00106\",\"cpd00027\",\"cpd00023\",\"cpd00053\",\"cpd30635\",\"cpd00229\",\"cpd10147\",\"cpd00040\",\"cpd00025\",\"cpd00119\",\"cpd22829\",\"cpd00039\",\"cpd20696\",\"cpd00428\",\"cf00002\",\"cpd00075\",\"cf00003\",\"cpd00007\",\"cpd00009\",\"cpd00016\",\"cpd00019\",\"cpd00017\",\"cpd00078\",\"cpd00081\",\"cpd00073\",\"cpd00001\",\"cpd00044\",\"cpd00202\",\"cpd00004\",\"cpd00003\",\"cpd00024\",\"cpd09249\",\"cpd00127\",\"cpd00045\",\"cpd00029\",\"cpd00936\",\"cpd00012\",\"cpd00895\",\"cpd00113\",\"cpd00359\",\"cpd00002\",\"cpd00008\",\"cpd00018\"\n",
    "]\n",
    "coreactant_drains = []\n",
    "coreactant_drain_hash = {}\n",
    "for reactant in coreactants:\n",
    "    reactant = reactant+\"_c0\"\n",
    "    if reactant not in model.metabolites:\n",
    "        print(\"Reactant not found:\"+reactant)\n",
    "        next\n",
    "    drain_reaction = utilities.add_drain_from_metabolite_id(\n",
    "        reactant,\n",
    "        -100,\n",
    "        100,\n",
    "        \"DM_\",\n",
    "        \"Demand for \"\n",
    "    )\n",
    "    if drain_reaction != None and drain_reaction.id not in model.reactions:\n",
    "        coreactant_drains.append(drain_reaction)\n",
    "    coreactant_drain_hash[drain_reaction.id] = [reactant,drain_reaction] \n",
    "model.add_reactions(coreactant_drains)\n",
    "print(\"1-done\")\n",
    "\n",
    "#Adding thermodynamic constraints\n",
    "utilities.add_simple_thermo_constraints()\n",
    "print(\"2-done\")\n",
    "\n",
    "#Adding metabolomics constraints\n",
    "drain_fluxes = utilities.add_intracellular_metabolomics_constraints(peakstring,builder)\n",
    "print(\"3-done\")\n",
    "\n",
    "#Setting objective function\n",
    "target_reaction = None\n",
    "if params[\"target_reaction\"][0:3] == \"bio\":\n",
    "    target_reaction = model.reactions.get_by_id(params[\"target_reaction\"]+\"_biomass\")\n",
    "else:\n",
    "    target_reaction = model.reactions.get_by_id(params[\"target_reaction\"])\n",
    "sense = \"max\"\n",
    "if params[\"max\"] == 0:\n",
    "    sense = \"min\"\n",
    "biomass_objective = model.problem.Objective(\n",
    "    1 * target_reaction.flux_expression,\n",
    "    direction=sense)\n",
    "model.objective = biomass_objective\n",
    "print(\"4-done\")\n",
    "\n",
    "#Setting metabolomics objective\n",
    "if target_reaction != None:\n",
    "    target_reaction.lower_bound = 0.1\n",
    "metabolite_objective = model.problem.Objective(\n",
    "    Zero,\n",
    "    direction=\"max\")\n",
    "obj_coef = dict()\n",
    "for peak in utilities.metabolomics_peak_variables:\n",
    "    obj_coef[utilities.metabolomics_peak_variables[peak]] = 1\n",
    "model.objective = metabolite_objective\n",
    "metabolite_objective.set_linear_coefficients(obj_coef)\n",
    "print(\"6-done\")\n",
    "\n",
    "#Printing LP file\n",
    "with open('GapfillSimpleThermoMetabolite.lp', 'w') as out:\n",
    "    out.write(str(model.solver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizing active metabolites\n",
    "maxmet_solution = model.optimize()\n",
    "print(maxmet_solution.objective_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constraining objective\n",
    "max_metabolite_constraint = model.problem.Constraint(\n",
    "    #Zero,lb=maxmet_solution.objective_value,ub=maxmet_solution.objective_value,name=\"max_metabolite_constraint\"\n",
    "    Zero,lb=236,ub=236,name=\"max_metabolite_constraint\"\n",
    ")\n",
    "model.add_cons_vars(max_metabolite_constraint)\n",
    "model.solver.update()\n",
    "obj_coef = dict()\n",
    "for peak in utilities.metabolomics_peak_variables:\n",
    "    obj_coef[utilities.metabolomics_peak_variables[peak]] = 1\n",
    "max_metabolite_constraint.set_linear_coefficients(obj_coef)\n",
    "\n",
    "#Printing LP file\n",
    "with open('GapfillSimpleThermoMetaboliteFixed.lp', 'w') as out:\n",
    "    out.write(str(model.solver))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new objective to minimize reactions of all types\n",
    "reaction_objective = model.problem.Objective(\n",
    "    Zero,\n",
    "    direction=\"min\")\n",
    "obj_coef = dict()\n",
    "for reaction in model.reactions:\n",
    "    if reaction.id in drain_fluxes:\n",
    "        #REALLY minimizing drain fluxes\n",
    "        obj_coef[reaction.reverse_variable] = 1000\n",
    "        obj_coef[reaction.forward_variable] = 1000\n",
    "    elif reaction.id[0:5] == \"spont\":\n",
    "        obj_coef[reaction.reverse_variable] = 1\n",
    "        obj_coef[reaction.forward_variable] = 1\n",
    "    elif reaction.id in coreactant_drain_hash:\n",
    "        if coreactant_drain_hash[reaction.id][0] in original_metabolites:\n",
    "            obj_coef[reaction.reverse_variable] = 100\n",
    "            obj_coef[reaction.forward_variable] = 100\n",
    "        else:\n",
    "            obj_coef[reaction.reverse_variable] = 3\n",
    "            obj_coef[reaction.forward_variable] = 3\n",
    "    elif reaction.id in penalties:\n",
    "        #Minimizing gapfilled reactions\n",
    "        if \"reverse\" in penalties[reaction.id]:\n",
    "            obj_coef[reaction.reverse_variable] = abs(penalties[reaction.id][\"reverse\"])\n",
    "        else:\n",
    "            obj_coef[reaction.reverse_variable] = 0.1\n",
    "        if \"forward\" in penalties[reaction.id]:\n",
    "            obj_coef[reaction.forward_variable] = abs(penalties[reaction.id][\"forward\"])\n",
    "        else:\n",
    "            obj_coef[reaction.forward_variable] = 0.1\n",
    "    elif reaction.id[0:3].lower() != \"ex_\" and reaction.id[0:3].lower() != \"dm_\":\n",
    "        #Minimizing all other reactions\n",
    "        obj_coef[reaction.reverse_variable] = 0.1\n",
    "        obj_coef[reaction.forward_variable] = 0.1\n",
    "model.objective = reaction_objective\n",
    "reaction_objective.set_linear_coefficients(obj_coef)\n",
    "\n",
    "#Printing LP file\n",
    "with open('GapfillSimpleThermoMetaboliteFixedObj.lp', 'w') as out:\n",
    "    out.write(str(model.solver))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizing active reactions\n",
    "minrxnsolution = model.optimize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelflux:152\n",
      "modelseedflux:208\n",
      "exchange:166\n",
      "drain:7\n",
      "enz:84\n",
      "spont:74\n"
     ]
    }
   ],
   "source": [
    "solution_data = \"\"\n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/MetabolomicsMethods/JCVI_fluxes.txt', 'r') as solution_file:\n",
    "    solution_data = solution_file.read()\n",
    "\n",
    "line_array = solution_data.split(\"\\n\")\n",
    "reaction_fluxes = dict()\n",
    "drain_fluxes = dict()\n",
    "exchange_fluxes = dict()\n",
    "modelflux = 0\n",
    "modelseedflux = 0\n",
    "exchange = 0\n",
    "drain = 0\n",
    "enz = 0\n",
    "spont = 0\n",
    "for line in line_array:\n",
    "    array = line.split(\"\\t\")\n",
    "    varname = array[0]\n",
    "    varname = varname.split(\"#\")[0]\n",
    "    vartype = \"rxn\"\n",
    "    if len(array) >= 2:\n",
    "        flux = float(array[1])\n",
    "        if re.search('^rxn\\d+_[a-z]\\d+$', varname) != None: \n",
    "            if varname in original_reactions:\n",
    "                modelflux += 1\n",
    "            else:\n",
    "                modelseedflux += 1\n",
    "        elif re.search('^(rxn\\d+_[a-z]\\d+)_reverse_[a-z0-9]+$', varname) != None:\n",
    "            m = re.search('^(rxn\\d+_[a-z]\\d+)_reverse_[a-z0-9]+$', varname)\n",
    "            varname = m[1]\n",
    "            flux = -1*float(array[1])\n",
    "            if varname in original_reactions:\n",
    "                modelflux += 1\n",
    "            else:\n",
    "                modelseedflux += 1\n",
    "        elif re.search('^(DM_.+)$', varname) != None:\n",
    "            m = re.search('^(DM_.+)$', varname)\n",
    "            vartype = \"dm\"\n",
    "            varname = m[1]\n",
    "            drain += 1\n",
    "        elif re.search('^_(EX_.+)_reverse_[a-z0-9]+$', varname) != None:\n",
    "            m = re.search('^_(EX_.+)_reverse_[a-z0-9]+$', varname)\n",
    "            vartype = \"ex\"\n",
    "            varname = m[1]\n",
    "            flux = -1*float(array[1])\n",
    "            exchange += 1\n",
    "        elif re.search('^_(EX_.+)$', varname) != None:\n",
    "            m = re.search('^_(EX_.+)$', varname)\n",
    "            vartype = \"ex\"\n",
    "            varname = m[1]\n",
    "            exchange += 1\n",
    "        elif re.search('^_(enzr\\d+_c0)$', varname) != None:\n",
    "            m = re.search('^_(enzr\\d+_c0)$', varname)\n",
    "            varname = m[1]\n",
    "            enz += 1\n",
    "        elif re.search('^(spontr\\d+_c0)$', varname) != None:\n",
    "            m = re.search('^(spontr\\d+_c0)$', varname)\n",
    "            varname = m[1]\n",
    "            spont += 1\n",
    "        elif re.search('^_(enzr\\d+_c0_reverse_[a-z0-9]+)$', varname) != None:\n",
    "            m = re.search('^_(enzr\\d+_c0_reverse_[a-z0-9]+)$', varname)\n",
    "            varname = m[1]\n",
    "            flux = -1*float(array[1])\n",
    "            enz += 1\n",
    "        elif re.search('^(spontr\\d+_c0)_reverse_[a-z0-9]+$', varname) != None:\n",
    "            m = re.search('^(spontr\\d+_c0)_reverse_[a-z0-9]+$', varname)\n",
    "            varname = m[1]\n",
    "            flux = -1*float(array[1])\n",
    "            spont += 1\n",
    "        elif re.search('^_*([A-Za-z0-9-]+_c0)$', varname) != None:\n",
    "            m = re.search('^_*([A-Za-z0-9-]+_c0)$', varname)\n",
    "            varname = m[1]\n",
    "            modelflux += 1\n",
    "        elif re.search('^_*([A-Za-z0-9-]+_c0)_reverse_[a-z0-9]+$', varname) != None:\n",
    "            m = re.search('^_*([A-Za-z0-9-]+_c0)_reverse_[a-z0-9]+$', varname)\n",
    "            varname = m[1]\n",
    "            flux = -1*float(array[1])\n",
    "            modelflux += 1\n",
    "        if vartype == \"rxn\":\n",
    "            if varname in model.reactions:\n",
    "                reaction_fluxes[varname] = flux\n",
    "            #else:\n",
    "                #print(varname+\" reaction not in model!\")\n",
    "        elif vartype == \"ex\":\n",
    "            if varname in model.metabolites:\n",
    "                exchange_fluxes[varname] = flux\n",
    "            #else:\n",
    "                #print(varname+\" exchange not in model!\")\n",
    "        elif vartype == \"dm\":\n",
    "            if varname in model.metabolites:\n",
    "                drain_fluxes[varname] = flux\n",
    "            #else:\n",
    "                #print(varname+\" drain not in model!\")\n",
    "                \n",
    "#Removing gapfilled reactions that have no flux\n",
    "metabolite_hash = {}\n",
    "reaction_list = []\n",
    "for reaction in model.reactions:\n",
    "    if reaction.id in original_reactions or reaction.id in reaction_fluxes or reaction.id in drain_fluxes or reaction.id in exchange_fluxes:\n",
    "        reaction_list.append(reaction)\n",
    "        for metabolite in reaction.metabolites:\n",
    "            metabolite_hash[metabolite.id] = metabolite\n",
    "new_model = Model(\"Expanded MMSyn3 model\")\n",
    "new_model.genes = model.genes\n",
    "new_model.add_metabolites(metabolite_hash.values())\n",
    "new_model.add_reactions(reaction_list)\n",
    "\n",
    "#Printing model in json format\n",
    "cobra.io.save_json_model(new_model, \"expanded_jcvi.json\")\n",
    "#Printing fluxes in TSV format\n",
    "file = open(\"expanded_jcvi_fluxes.csv\",\"w\") \n",
    "file.write(\"reaction,flux\\n\")\n",
    "for reaction in reaction_fluxes:\n",
    "    flux = reaction_fluxes[reaction]\n",
    "    if reaction in original_reactions:\n",
    "        flux += 10\n",
    "    elif re.search('spontr', reaction):\n",
    "        flux += 100\n",
    "    elif re.search('enzr', reaction):\n",
    "        flux += 10000    \n",
    "    elif re.search('rxn\\d\\d\\d\\d\\d', reaction):\n",
    "        flux += 1000\n",
    "    file.write(reaction+\",\"+str(flux)+\"\\n\")\n",
    "for reaction in exchange_fluxes:\n",
    "    flux = exchange_fluxes[reaction]\n",
    "    if reaction in original_reactions:\n",
    "        flux += 10\n",
    "    else:\n",
    "        flux += 100\n",
    "    file.write(reaction+\",\"+str(flux)+\"\\n\")\n",
    "for reaction in drain_fluxes:\n",
    "    flux = drain_fluxes[reaction]\n",
    "    if reaction in original_reactions:\n",
    "        flux += 10\n",
    "    else:\n",
    "        flux += 100\n",
    "    file.write(reaction+\",\"+str(flux)+\"\\n\")\n",
    "file.close()\n",
    "\n",
    "print(\"modelflux:\"+str(modelflux))\n",
    "print(\"modelseedflux:\"+str(modelseedflux))\n",
    "print(\"exchange:\"+str(exchange))\n",
    "print(\"drain:\"+str(drain))\n",
    "print(\"enz:\"+str(enz))\n",
    "print(\"spont:\"+str(spont))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rxn01548_c0 repeated:0.0005;-0.0005\n",
      "rxn01859_c0 repeated:6.9e-05;-0.000406\n",
      "rxn01446_c0 repeated:0.0005;-0.0005\n",
      "rxn01513_c0 repeated:0.0005;-0.000337\n",
      "rxn01127_c0 repeated:0.000406;-0.0005\n",
      "rxn01322_c0 repeated:0.0005;-0.0005\n",
      "rxn01374_c0 repeated:0.0005;-0.0005\n",
      "rxn12846_c0 repeated:0.0005;-0.0005\n",
      "rxn01729_c0 repeated:0.0005;-0.0005\n",
      "rxn08471_c0 repeated:0.0005;-0.0005\n",
      "rxn00514_c0 repeated:0.0005;-0.0005\n",
      "rxn09265_c0 repeated:0.0005;-0.0005\n",
      "rxn00758_c0 repeated:0.0005;-0.0005\n",
      "rxn12847_c0 repeated:0.0005;-0.0005\n",
      "rxn04068_c0 repeated:0.0005;-0.0005\n",
      "rxn00879_c0 repeated:0.0005;-0.0005\n",
      "rxn02275_c0 repeated:0.0005;-0.0005\n",
      "rxn01531_c0 repeated:0.0005;-0.0005\n",
      "rxn03484_c0 repeated:0.0005;-0.0005\n",
      "rxn02414_c0 repeated:0.0005;-0.0005\n",
      "rxn02028_c0 repeated:0.00025;-0.00075\n",
      "rxn00751_c0 repeated:0.0005;-0.0005\n",
      "rxn00941_c0 repeated:0.000163;-0.000174\n",
      "rxn06077_c0 repeated:0.0005;-0.0005\n",
      "rxn00469_c0 repeated:0.00025;-0.00025\n",
      "rxn00160_c0 repeated:0.00025;-0.00025\n",
      "rxn03339_c0 repeated:0.0005;-0.0005\n",
      "rxn01537_c0 repeated:0.0005;-0.0005\n",
      "rxn01704_c0 repeated:0.0005;-0.0005\n",
      "rxn02085_c0 repeated:0.0005;-0.0005\n",
      "rxn03841_c0 repeated:0.0005;-0.0005\n",
      "rxn12642_c0 repeated:0.0005;-0.0005\n",
      "rxn01252_c0 repeated:0.0005;-0.0005\n",
      "rxn02463_c0 repeated:0.000498;-0.0005\n",
      "rxn12635_c0 repeated:0.0005;-0.0005\n",
      "rxn02296_c0 repeated:0.0005;-0.0005\n",
      "rxn00720_c0 repeated:0.0005;-0.0005\n",
      "rxn01551_c0 repeated:0.0005;-0.0005\n",
      "rxn10753_c0 repeated:0.0005;-0.0005\n",
      "rxn02392_c0 repeated:0.0005;-0.0005\n",
      "rxn02518_c0 repeated:0.0005;-0.0005\n",
      "rxn02222_c0 repeated:0.0005;-0.0005\n",
      "rxn01080_c0 repeated:0.0005;-0.0005\n",
      "rxn01019_c0 repeated:0.00025;-0.00025\n",
      "rxn02914_c0 repeated:0.0005;-0.0005\n",
      "rxn02246_c0 repeated:0.0005;-0.0005\n",
      "Peaks:236\n",
      "Reactions:102489\n",
      "Distinct reaction:102443\n",
      "Previous cpd match:cpd00138_c0;cpd00027_c0\n",
      "Previous cpd match:enzc1481_c0;cpd00218_c0\n",
      "Previous cpd match:enzc2067_c0;cpd00009_c0\n",
      "Previous cpd match:cpd01755_c0;cpd00492_c0\n",
      "Previous cpd match:enzc2539_c0;cpd00274_c0\n",
      "Previous cpd match:enzc522_c0;cpd00010_c0\n",
      "Previous cpd match:enzc20_c0;thfglu3_c0\n",
      "Previous cpd match:enzc1112_c0;cpd00024_c0\n",
      "Previous cpd match:enzc1949_c0;cpd00182_c0\n",
      "Previous cpd match:enzc1997_c0;cpd00293_c0\n",
      "Previous cpd match:enzc30_c0;cpd00022_c0\n",
      "Previous cpd match:enzc2543_c0;cpd00220_c0\n",
      "Previous cpd match:enzc2329_c0;cpd02197_c0\n",
      "Previous cpd match:enzc227_c0;cpd00012_c0\n",
      "Previous cpd match:enzc704_c0;cpd00213_c0\n",
      "Previous cpd match:enzc1216_c0;enzc1357_c0\n",
      "Previous cpd match:enzc1848_c0;cpd00013_c0\n",
      "Previous cpd match:cpd00040_c0;cpd00040_c0\n",
      "Previous cpd match:cpd00106_c0;cpd00106_c0\n",
      "Previous cpd match:cpd01160_c0;cpd01160_c0\n",
      "Previous cpd match:cpd26525_c0;cpd21209_c0\n",
      "Previous cpd match:cpd17158_c0;cpd17158_c0\n",
      "Previous cpd match:cpd00771_c0;cpd00771_c0\n",
      "Previous cpd match:cpd24585_c0;cpd01770_c0\n",
      "Previous cpd match:spontc254_c0;cpd00035_c0\n",
      "Previous cpd match:cpd09352_c0;cpd09352_c0\n",
      "Previous cpd match:spontc395_c0;cpd00299_c0\n",
      "Previous cpd match:spontc481_c0;cpd00041_c0\n",
      "Previous cpd match:spontc527_c0;cpd00249_c0\n",
      "Previous cpd match:spontc550_c0;cpd00114_c0\n",
      "Previous cpd match:cpd21208_c0;cpd21208_c0\n",
      "Previous cpd match:spontc606_c0;cpd00412_c0\n",
      "Previous cpd match:cpd09048_c0;cpd09048_c0\n",
      "Previous cpd match:spontc738_c0;cpd00133_c0\n",
      "Previous cpd match:cpd01901_c0;cpd01901_c0\n",
      "Previous cpd match:cpd02418_c0;cpd02418_c0\n",
      "Previous cpd match:spontc899_c0;cpd03704_c0\n",
      "Previous cpd match:cpd19002_c0;cpd00023_c0\n",
      "Previous cpd match:cpd00752_c0;cpd00752_c0\n",
      "Previous cpd match:cpd15394_c0;cpd15394_c0\n",
      "Previous cpd match:spontc1009_c0;cpd09352_c0\n",
      "Previous cpd match:spontc1020_c0;cpd00169_c0\n",
      "Previous cpd match:spontc1133_c0;cpd00274_c0\n",
      "Previous cpd match:spontc1149_c0;cpd00060_c0\n",
      "Previous cpd match:spontc1227_c0;cpd00091_c0\n",
      "Previous cpd match:cpd01018_c0;cpd00381_c0\n",
      "Previous cpd match:spontc721_c0;enzc1611_c0\n",
      "Previous cpd match:spontc246_c0;enzc1588_c0\n",
      "Previous cpd match:spontc240_c0;enzc2118_c0\n",
      "Previous cpd match:spontc227_c0;enzc1720_c0\n",
      "Previous cpd match:spontc15_c0;enzc1129_c0\n",
      "Previous cpd match:spontc268_c0;enzc497_c0\n",
      "Previous cpd match:spontc572_c0;cpd02147_c0\n",
      "Previous cpd match:spontc590_c0;cpd00032_c0\n",
      "Previous cpd match:spontc1235_c0;enzc2379_c0\n",
      "Previous cpd match:spontc49_c0;enzc2298_c0\n",
      "Previous cpd match:spontc190_c0;enzc2376_c0\n",
      "Previous cpd match:spontc50_c0;enzc1003_c0\n",
      "Previous cpd match:spontc397_c0;cpd00477_c0\n",
      "Previous cpd match:spontc1253_c0;enzc1560_c0\n",
      "Previous cpd match:spontc273_c0;enzc1460_c0\n",
      "Previous cpd match:spontc870_c0;enzc570_c0\n",
      "Previous cpd match:spontc608_c0;enzc427_c0\n",
      "Previous cpd match:spontc381_c0;enzc2255_c0\n",
      "Previous cpd match:spontc263_c0;enzc2524_c0\n",
      "Previous cpd match:spontc846_c0;cpd00251_c0\n",
      "Previous cpd match:spontc1135_c0;enzc2451_c0\n",
      "Previous cpd match:spontc1214_c0;cpd00978_c0\n",
      "Previous cpd match:spontc992_c0;enzc631_c0\n",
      "Previous cpd match:spontc52_c0;enzc989_c0\n",
      "Previous cpd match:spontc269_c0;cpd00090_c0\n",
      "Previous cpd match:spontc896_c0;cpd00638_c0\n",
      "Previous cpd match:spontc1110_c0;enzc1057_c0\n",
      "Previous cpd match:spontc119_c0;enzc1929_c0\n",
      "Previous cpd match:spontc505_c0;enzc2526_c0\n",
      "Previous cpd match:spontc132_c0;enzc1508_c0\n",
      "Previous cpd match:spontc1126_c0;enzc1675_c0\n",
      "Previous cpd match:spontc641_c0;enzc383_c0\n",
      "Previous cpd match:spontc894_c0;enzc195_c0\n",
      "Previous cpd match:spontc392_c0;cpd02074_c0\n",
      "Previous cpd match:spontc952_c0;enzc596_c0\n",
      "Previous cpd match:spontc542_c0;enzc98_c0\n",
      "Previous cpd match:spontc830_c0;enzc1051_c0\n",
      "Previous cpd match:spontc1164_c0;enzc405_c0\n",
      "Previous cpd match:spontc221_c0;cpd00020_c0\n",
      "Previous cpd match:spontc1187_c0;enzc391_c0\n",
      "Previous cpd match:spontc166_c0;enzc108_c0\n",
      "Previous cpd match:spontc1270_c0;enzc2454_c0\n",
      "Previous cpd match:spontc1018_c0;enzc985_c0\n",
      "Previous cpd match:spontc502_c0;cpd00029_c0\n",
      "Previous cpd match:spontc226_c0;spontc194_c0\n",
      "Previous cpd match:spontc916_c0;enzc800_c0\n",
      "Previous cpd match:spontc554_c0;enzc2232_c0\n",
      "Previous cpd match:spontc1266_c0;cpd00767_c0\n",
      "Previous cpd match:spontc1124_c0;cpd00977_c0\n",
      "Previous cpd match:spontc78_c0;enzc751_c0\n",
      "Previous cpd match:spontc113_c0;enzc360_c0\n",
      "Previous cpd match:spontc102_c0;cpd00014_c0\n",
      "Previous cpd match:spontc312_c0;cpd00976_c0\n",
      "Previous cpd match:spontc410_c0;enzc235_c0\n",
      "Previous cpd match:spontc156_c0;enzc2527_c0\n",
      "Previous cpd match:spontc26_c0;enzc220_c0\n",
      "Previous cpd match:spontc285_c0;cpd02069_c0\n",
      "Previous cpd match:spontc799_c0;enzc267_c0\n",
      "Previous cpd match:spontc643_c0;enzc159_c0\n",
      "Previous cpd match:spontc975_c0;enzc29_c0\n",
      "Previous cpd match:spontc258_c0;enzc269_c0\n",
      "Previous cpd match:spontc881_c0;enzc747_c0\n",
      "Previous cpd match:spontc432_c0;enzc2302_c0\n",
      "Previous cpd match:spontc288_c0;cpd00024_c0\n",
      "Previous cpd match:spontc1155_c0;enzc613_c0\n",
      "Previous cpd match:spontc539_c0;cpd00062_c0\n",
      "Previous cpd match:spontc716_c0;enzc237_c0\n",
      "Previous cpd match:spontc1095_c0;enzc828_c0\n",
      "Previous cpd match:spontc733_c0;enzc2107_c0\n",
      "Previous cpd match:spontc900_c0;spontc396_c0\n",
      "Previous cpd match:spontc65_c0;enzc1973_c0\n",
      "Previous cpd match:spontc854_c0;enzc1587_c0\n",
      "Previous cpd match:spontc744_c0;enzc967_c0\n",
      "Previous cpd match:spontc411_c0;cpd02079_c0\n",
      "Previous cpd match:spontc1050_c0;enzc633_c0\n",
      "Previous cpd match:spontc428_c0;enzc1234_c0\n",
      "Previous cpd match:spontc1229_c0;enzc4_c0\n",
      "Previous cpd match:spontc1098_c0;enzc121_c0\n",
      "Previous cpd match:spontc939_c0;enzc2040_c0\n",
      "Previous cpd match:spontc1224_c0;enzc19_c0\n",
      "Previous cpd match:spontc929_c0;enzc767_c0\n",
      "Previous cpd match:spontc871_c0;enzc857_c0\n",
      "Previous cpd match:spontc667_c0;cpd09365_c0\n",
      "Previous cpd match:spontc404_c0;enzc539_c0\n",
      "Previous cpd match:spontc1215_c0;spontc742_c0\n",
      "Previous cpd match:spontc140_c0;enzc1336_c0\n",
      "Previous cpd match:spontc607_c0;enzc278_c0\n",
      "Previous cpd match:spontc694_c0;cpd00078_c0\n",
      "Previous cpd match:spontc986_c0;enzc2478_c0\n",
      "Previous cpd match:spontc915_c0;enzc2153_c0\n",
      "Previous cpd match:spontc267_c0;enzc259_c0\n",
      "Previous cpd match:spontc980_c0;enzc2082_c0\n",
      "Previous cpd match:spontc92_c0;enzc964_c0\n",
      "Previous cpd match:spontc478_c0;cpd00358_c0\n",
      "Previous cpd match:spontc1134_c0;enzc2512_c0\n",
      "Previous cpd match:spontc598_c0;enzc949_c0\n",
      "Previous cpd match:spontc358_c0;enzc1829_c0\n",
      "Previous cpd match:spontc710_c0;enzc2229_c0\n",
      "Previous cpd match:spontc594_c0;cpd00293_c0\n",
      "Previous cpd match:spontc152_c0;spontc329_c0\n",
      "Previous cpd match:spontc1058_c0;enzc277_c0\n",
      "Previous cpd match:spontc96_c0;enzc1094_c0\n",
      "Previous cpd match:spontc618_c0;enzc2130_c0\n",
      "Previous cpd match:spontc196_c0;enzc527_c0\n",
      "Previous cpd match:spontc448_c0;enzc1357_c0\n",
      "Previous cpd match:spontc244_c0;enzc477_c0\n",
      "Previous cpd match:spontc280_c0;enzc1966_c0\n",
      "Previous cpd match:spontc284_c0;enzc2155_c0\n",
      "Previous cpd match:spontc921_c0;enzc2462_c0\n",
      "Previous cpd match:spontc851_c0;enzc1960_c0\n",
      "Previous cpd match:spontc112_c0;enzc1324_c0\n",
      "Previous cpd match:spontc510_c0;enzc880_c0\n",
      "Previous cpd match:spontc578_c0;enzc1673_c0\n",
      "Previous cpd match:spontc1064_c0;spontc574_c0\n",
      "Previous cpd match:spontc1218_c0;spontc948_c0\n",
      "Previous cpd match:spontc1246_c0;enzc2248_c0\n",
      "Previous cpd match:spontc387_c0;enzc1897_c0\n",
      "Previous cpd match:spontc891_c0;enzc977_c0\n",
      "Previous cpd match:spontc77_c0;cpd00068_c0\n",
      "Previous cpd match:spontc169_c0;enzc21_c0\n",
      "Previous cpd match:cpd00147_c0;cpd00147_c0\n",
      "Previous cpd match:enzc6388_c0;cpd00206_c0\n",
      "Previous cpd match:cpd15140_c0;cpd00129_c0\n",
      "Previous cpd match:enzc7776_c0;cpd00095_c0\n",
      "Previous cpd match:cpd19005_c0;cpd00102_c0\n",
      "Previous cpd match:cpd19182_c0;cpd00039_c0\n",
      "Previous cpd match:cpd19034_c0;cpd00135_c0\n",
      "Previous cpd match:enzc11923_c0;cpd00246_c0\n",
      "Previous cpd match:cpd30746_c0;cpd00060_c0\n",
      "Previous cpd match:cpd30743_c0;cpd00054_c0\n",
      "Previous cpd match:enzc18490_c0;cpd00988_c0\n",
      "Previous cpd match:enzc19795_c0;cpd00003_c0\n",
      "Previous cpd match:enzc20772_c0;cpd00017_c0\n",
      "Previous cpd match:cpd19025_c0;cpd00089_c0\n",
      "Previous cpd match:cpd01573_c0;cpd01573_c0\n",
      "Previous cpd match:cpd01400_c0;cpd00066_c0\n",
      "Previous cpd match:enzc25627_c0;cpd00299_c0\n",
      "Previous cpd match:enzc31246_c0;cpd00018_c0\n",
      "Previous cpd match:enzc31756_c0;cpd00298_c0\n",
      "Previous cpd match:enzc33155_c0;cpd00126_c0\n",
      "Previous cpd match:enzc33914_c0;cpd00482_c0\n",
      "Previous cpd match:cpd15139_c0;cpd00322_c0\n",
      "Previous cpd match:enzc41367_c0;cpd00184_c0\n",
      "Previous cpd match:enzc46122_c0;cpd00023_c0\n",
      "Previous cpd match:enzc50799_c0;cpd00091_c0\n",
      "Previous cpd match:cpd15143_c0;cpd00107_c0\n",
      "Previous cpd match:cpd19021_c0;cpd00051_c0\n",
      "Previous cpd match:cpd15142_c0;cpd00132_c0\n",
      "Previous cpd match:enzc56862_c0;cpd00128_c0\n",
      "Previous cpd match:cpd02131_c0;cpd02131_c0\n",
      "Previous cpd match:cpd00572_c0;cpd00119_c0\n",
      "Previous cpd match:enzc59650_c0;cpd00342_c0\n",
      "Previous cpd match:enzc60510_c0;cpd00039_c0\n",
      "Previous cpd match:enzc60617_c0;cpd00079_c0\n",
      "Previous cpd match:enzc61599_c0;cpd00003_c0\n",
      "Previous cpd match:enzc62617_c0;cpd00026_c0\n",
      "Previous cpd match:cpd00548_c0;cpd00027_c0\n",
      "Previous cpd match:enzc67158_c0;cpd00169_c0\n",
      "Previous cpd match:enzc68313_c0;cpd00018_c0\n",
      "Previous cpd match:enzc68379_c0;cpd00290_c0\n",
      "Previous cpd match:cpd00253_c0;cpd00053_c0\n",
      "Previous cpd match:enzc71317_c0;cpd00276_c0\n",
      "Previous cpd match:cpd15141_c0;cpd00156_c0\n",
      "Previous cpd match:cpd00547_c0;cpd00084_c0\n",
      "Previous cpd match:enzc76407_c0;cpd00294_c0\n",
      "Previous cpd match:enzc78342_c0;cpd01756_c0\n",
      "Previous cpd match:cpd19007_c0;cpd00065_c0\n",
      "Previous cpd match:cpd02522_c0;cpd01046_c0\n",
      "Previous cpd match:enzc83825_c0;cpd00080_c0\n",
      "Previous cpd match:enzc88906_c0;cpd00046_c0\n",
      "Previous cpd match:enzc90856_c0;enzc701_c0\n",
      "Previous cpd match:cpd30745_c0;cpd00069_c0\n",
      "Previous cpd match:enzc45470_c0;enzc991_c0\n",
      "Previous cpd match:enzc85252_c0;enzc999_c0\n",
      "Previous cpd match:cpd27177_c0;cpd00023_c0\n",
      "Previous cpd match:spontc2436_c0;cpd12732_c0\n",
      "Previous cpd match:cpd02226_c0;cpd02226_c0\n",
      "Previous cpd match:cpd01003_c0;cpd00035_c0\n",
      "Previous cpd match:cpd02268_c0;cpd02268_c0\n",
      "Previous cpd match:cpd27874_c0;cpd00738_c0\n",
      "Previous cpd match:cpd00133_c0;cpd00133_c0\n",
      "Previous cpd match:spontc8282_c0;cpd03460_c0\n",
      "Previous cpd match:spontc10586_c0;cpd00023_c0\n",
      "Previous cpd match:spontc11540_c0;cpd00033_c0\n",
      "Previous cpd match:cpd19181_c0;cpd00041_c0\n",
      "Previous cpd match:spontc13310_c0;enzc2099_c0\n",
      "Previous cpd match:cpd21912_c0;cpd21912_c0\n",
      "Previous cpd match:spontc15938_c0;cpd19028_c0\n",
      "Previous cpd match:spontc16837_c0;cpd01764_c0\n",
      "Previous cpd match:cpd00251_c0;cpd00251_c0\n",
      "Previous cpd match:spontc20632_c0;cpd02636_c0\n",
      "Previous cpd match:spontc21923_c0;cpd00210_c0\n",
      "Previous cpd match:cpd30741_c0;cpd00169_c0\n",
      "Previous cpd match:spontc22537_c0;cpd00036_c0\n",
      "Previous cpd match:spontc23365_c0;cpd00218_c0\n",
      "Previous cpd match:spontc17718_c0;spontc184_c0\n",
      "Previous cpd match:spontc23938_c0;spontc1281_c0\n",
      "Previous cpd match:spontc23968_c0;spontc484_c0\n",
      "Previous cpd match:spontc6350_c0;methfglu3_c0\n",
      "Previous cpd match:spontc7630_c0;enzc42844_c0\n",
      "Previous cpd match:spontc10678_c0;enzc55439_c0\n",
      "Previous cpd match:spontc15643_c0;spontc446_c0\n",
      "Previous cpd match:spontc21908_c0;spontc976_c0\n",
      "Previous cpd match:spontc9165_c0;spontc28_c0\n",
      "Previous cpd match:spontc20731_c0;spontc1081_c0\n",
      "Previous cpd match:spontc15003_c0;spontc889_c0\n",
      "Previous cpd match:spontc2662_c0;spontc16261_c0\n",
      "Previous cpd match:spontc19404_c0;spontc15603_c0\n",
      "Previous cpd match:spontc10252_c0;enzc92506_c0\n",
      "Previous cpd match:spontc13449_c0;spontc1178_c0\n",
      "Previous cpd match:spontc13857_c0;spontc1225_c0\n",
      "Previous cpd match:spontc6295_c0;enzc57854_c0\n",
      "Previous cpd match:spontc21278_c0;enzc763_c0\n",
      "Previous cpd match:spontc15728_c0;spontc584_c0\n",
      "Previous cpd match:spontc16290_c0;spontc342_c0\n",
      "Previous cpd match:spontc12002_c0;spontc789_c0\n",
      "Previous cpd match:spontc10392_c0;spontc948_c0\n",
      "Previous cpd match:spontc6328_c0;enzc69628_c0\n",
      "Previous cpd match:spontc5884_c0;spontc382_c0\n",
      "Previous cpd match:spontc14310_c0;spontc1168_c0\n",
      "Previous cpd match:spontc16725_c0;enzc21205_c0\n",
      "Previous cpd match:spontc24247_c0;cpd14792_c0\n",
      "Previous cpd match:spontc17047_c0;enzc51719_c0\n",
      "Previous cpd match:spontc11071_c0;spontc310_c0\n",
      "Previous cpd match:spontc23696_c0;spontc175_c0\n",
      "Previous cpd match:spontc21834_c0;5fthfglu3_c0\n",
      "Previous cpd match:spontc19191_c0;enzc65265_c0\n",
      "Previous cpd match:spontc14314_c0;enzc46031_c0\n",
      "Previous cpd match:spontc22302_c0;spontc2368_c0\n",
      "Previous cpd match:spontc8140_c0;spontc266_c0\n",
      "Previous cpd match:spontc6551_c0;spontc879_c0\n",
      "Previous cpd match:spontc12198_c0;spontc28_c0\n",
      "Previous cpd match:spontc10709_c0;spontc293_c0\n",
      "Previous cpd match:spontc5897_c0;spontc675_c0\n",
      "Previous cpd match:spontc7152_c0;spontc9538_c0\n",
      "Previous cpd match:spontc11009_c0;spontc329_c0\n",
      "Previous cpd match:spontc3050_c0;enzc462_c0\n",
      "Previous cpd match:spontc19237_c0;enzc82049_c0\n",
      "Previous cpd match:spontc5707_c0;spontc336_c0\n",
      "Previous cpd match:spontc10312_c0;spontc2332_c0\n",
      "Previous cpd match:spontc20526_c0;spontc17741_c0\n",
      "Previous cpd match:cpd00392_c0;cpd00392_c0\n",
      "Previous cpd match:enzc169682_c0;cpd00395_c0\n",
      "Previous cpd match:enzc177786_c0;enzc34087_c0\n",
      "Previous cpd match:enzc191060_c0;cpd01293_c0\n",
      "Previous cpd match:enzc205990_c0;cpd03460_c0\n",
      "Previous cpd match:enzc216915_c0;cpd00223_c0\n",
      "Previous cpd match:enzc218613_c0;cpd00114_c0\n",
      "Previous cpd match:enzc230666_c0;cpd19028_c0\n",
      "Previous cpd match:cpd23747_c0;cpd20927_c0\n",
      "Previous cpd match:cpd00448_c0;cpd00448_c0\n",
      "Previous cpd match:enzc279505_c0;cpd00889_c0\n",
      "Previous cpd match:enzc282843_c0;cpd00644_c0\n",
      "Previous cpd match:enzc374817_c0;cpd00771_c0\n",
      "Previous cpd match:enzc252634_c0;enzc1234_c0\n",
      "Previous cpd match:enzc121311_c0;enzc382_c0\n",
      "Previous cpd match:enzc172046_c0;enzc1944_c0\n",
      "Previous cpd match:enzc144938_c0;enzc57_c0\n",
      "Previous cpd match:enzc335388_c0;enzc71338_c0\n",
      "Previous cpd match:enzc288259_c0;spontc115_c0\n",
      "Previous cpd match:enzc123329_c0;enzc2515_c0\n",
      "Previous cpd match:enzc349009_c0;spontc757_c0\n",
      "Previous cpd match:cpd00591_c0;cpd00591_c0\n",
      "Previous cpd match:cpd27590_c0;cpd27590_c0\n",
      "Previous cpd match:spontc53914_c0;cpd03460_c0\n",
      "Previous cpd match:cpd01606_c0;cpd01606_c0\n",
      "Previous cpd match:spontc113322_c0;cpd00147_c0\n",
      "Previous cpd match:spontc115414_c0;cpd00226_c0\n",
      "Previous cpd match:spontc119902_c0;cpd00771_c0\n",
      "Previous cpd match:cpd27040_c0;cpd00082_c0\n",
      "Previous cpd match:spontc51246_c0;spontc16962_c0\n",
      "Previous cpd match:spontc109486_c0;spontc1044_c0\n",
      "Previous cpd match:spontc91666_c0;spontc364_c0\n",
      "Previous cpd match:spontc71063_c0;spontc869_c0\n",
      "Previous cpd match:spontc126939_c0;enzc246550_c0\n",
      "Previous cpd match:spontc104789_c0;spontc876_c0\n",
      "Previous cpd match:spontc100762_c0;spontc628_c0\n",
      "Previous cpd match:spontc113777_c0;spontc15310_c0\n",
      "Previous cpd match:spontc57556_c0;spontc1209_c0\n",
      "Previous cpd match:spontc119044_c0;spontc1170_c0\n",
      "Previous cpd match:enzc429062_c0;cpd01138_c0\n",
      "Previous cpd match:cpd16443_c0;cpd16443_c0\n",
      "Previous cpd match:enzc488559_c0;cpd00756_c0\n",
      "Previous cpd match:cpd00246_c0;cpd00246_c0\n",
      "Previous cpd match:enzc678526_c0;cpd00161_c0\n",
      "Previous cpd match:enzc679190_c0;cpd00482_c0\n",
      "Previous cpd match:enzc745830_c0;spontc3771_c0\n",
      "Previous cpd match:enzc568947_c0;spontc5123_c0\n",
      "Previous cpd match:enzc682324_c0;spontc3570_c0\n",
      "Previous cpd match:enzc920788_c0;enzc205200_c0\n",
      "Previous cpd match:cpd00381_c0;cpd00381_c0\n",
      "Previous cpd match:cpd02211_c0;cpd02211_c0\n",
      "Previous cpd match:enzc953614_c0;spontc49160_c0\n",
      "Previous cpd match:enzc1145270_c0;spontc71962_c0\n",
      "Previous cpd match:spontc464933_c0;enzc1265805_c0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flux count:182\n",
      "Active peak count:236\n"
     ]
    }
   ],
   "source": [
    "kbase_api = cobrakbase.KBaseAPI()\n",
    "\n",
    "#Loading fluxes into a hash\n",
    "flux_hash = {}\n",
    "solution_data = \"\"\n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/MetabolomicsMethods/JCVI_fluxes.txt', 'r') as solution_file:\n",
    "    solution_data = solution_file.read()\n",
    "line_array = solution_data.split(\"\\n\")\n",
    "count = 0\n",
    "peak_solution_hash = {}\n",
    "for line in line_array:\n",
    "    array = line.split(\"\\t\")\n",
    "    varname = array[0]\n",
    "    varname = varname.split(\"#\")[0] \n",
    "    if len(array) >= 2:\n",
    "        flux = float(array[1])\n",
    "        vartype = \"rxn\"\n",
    "        if re.search('^(peak\\.\\d+)',varname) != None:\n",
    "            m = re.search('^(peak\\.\\d+)', varname)\n",
    "            vartype = \"peak\"\n",
    "            varname = m[1]\n",
    "        elif re.search('^rxn\\d+_[a-z]\\d+$', varname) != None: \n",
    "            vartype = \"rxn\"\n",
    "        elif re.search('^(rxn\\d+_[a-z]\\d+)_reverse_[a-z0-9]+$', varname) != None:\n",
    "            m = re.search('^(rxn\\d+_[a-z]\\d+)_reverse_[a-z0-9]+$', varname)\n",
    "            vartype = \"rxn\"\n",
    "            varname = m[1]\n",
    "            flux = -1*float(array[1])\n",
    "        elif re.search('^(DM_.+)$', varname) != None:\n",
    "            m = re.search('^(DM_.+)$', varname)\n",
    "            vartype = \"dm\"\n",
    "            varname = m[1]\n",
    "        elif re.search('^_(EX_.+)_reverse_[a-z0-9]+$', varname) != None:\n",
    "            m = re.search('^_(EX_.+)_reverse_[a-z0-9]+$', varname)\n",
    "            vartype = \"ex\"\n",
    "            varname = m[1]\n",
    "            flux = -1*float(array[1])\n",
    "        elif re.search('^_(EX_.+)$', varname) != None:\n",
    "            m = re.search('^_(EX_.+)$', varname)\n",
    "            vartype = \"ex\"\n",
    "            varname = m[1]\n",
    "        elif re.search('^_(enzr\\d+_c0)$', varname) != None:\n",
    "            m = re.search('^_(enzr\\d+_c0)$', varname)\n",
    "            vartype = \"rxn\"\n",
    "            varname = m[1]\n",
    "        elif re.search('^(spontr\\d+_c0)$', varname) != None:\n",
    "            m = re.search('^(spontr\\d+_c0)$', varname)\n",
    "            vartype = \"rxn\"\n",
    "            varname = m[1]\n",
    "        elif re.search('^_(enzr\\d+_c0_reverse_[a-z0-9]+)$', varname) != None:\n",
    "            m = re.search('^_(enzr\\d+_c0_reverse_[a-z0-9]+)$', varname)\n",
    "            vartype = \"rxn\"\n",
    "            varname = m[1]\n",
    "            flux = -1*float(array[1])\n",
    "        elif re.search('^(spontr\\d+_c0)_reverse_[a-z0-9]+$', varname) != None:\n",
    "            m = re.search('^(spontr\\d+_c0)_reverse_[a-z0-9]+$', varname)\n",
    "            vartype = \"rxn\"\n",
    "            varname = m[1]\n",
    "            flux = -1*float(array[1])\n",
    "        elif re.search('^_*([A-Za-z0-9-]+_c0)$', varname) != None:\n",
    "            m = re.search('^_*([A-Za-z0-9-]+_c0)$', varname)\n",
    "            vartype = \"rxn\"\n",
    "            varname = m[1]\n",
    "        elif re.search('^_*([A-Za-z0-9-]+_c0)_reverse_[a-z0-9]+$', varname) != None:\n",
    "            m = re.search('^_*([A-Za-z0-9-]+_c0)_reverse_[a-z0-9]+$', varname)\n",
    "            vartype = \"rxn\"\n",
    "            varname = m[1]\n",
    "            flux = -1*float(array[1])\n",
    "            modelflux += 1\n",
    "        varname = varname.replace(\"__DASH__\",\"-\")\n",
    "        if vartype == \"rxn\":\n",
    "            count += 1\n",
    "            corrected_flux = None\n",
    "            if varname in flux_hash:\n",
    "                print(varname+\" repeated:\"+str(flux_hash[varname])+\";\"+str(flux))\n",
    "                if flux_hash[varname] == -1*flux:\n",
    "                     corrected_flux = 0\n",
    "            flux_hash[varname] = flux\n",
    "            if corrected_flux != None:\n",
    "                flux_hash[varname] = 0\n",
    "        elif vartype == \"peak\":\n",
    "            if varname in peak_solution_hash:\n",
    "                print(\"Repeat peak:\"+varname)\n",
    "            peak_solution_hash[varname] = flux\n",
    "\n",
    "print(\"Peaks:\"+str(len(peak_solution_hash.keys())))\n",
    "print(\"Reactions:\"+str(count))\n",
    "print(\"Distinct reaction:\"+str(len(flux_hash.keys())))       \n",
    "#Loading ModelSEED reactions and compounds\n",
    "baseinchi_all = {}\n",
    "baseinchi_modelseed_hash = {}\n",
    "modelseed_rxn_hash = {}\n",
    "modelseed_cpd_hash = {}\n",
    "with open('/Users/chenry/code/fba_tools/data/Reactions.json') as json_file:\n",
    "    input_data = json.load(json_file)\n",
    "    for rxn in input_data:\n",
    "        modelseed_rxn_hash[rxn[\"id\"]+\"_c0\"] = rxn\n",
    "with open('/Users/chenry/code/fba_tools/data/Compounds.json') as json_file:\n",
    "    input_data = json.load(json_file)\n",
    "    for cpd in input_data:\n",
    "        modelseed_cpd_hash[cpd[\"id\"]] = cpd\n",
    "        cpd[\"reactions\"] = 0\n",
    "        cpd[\"peaks\"] = {}\n",
    "        cpd[\"baseinchi\"] = \"\"\n",
    "        if \"inchikey\" in cpd:\n",
    "            cpd[\"baseinchi\"] = cpd[\"inchikey\"].split(\"-\")[0]\n",
    "    #Adding reactions counts to ModelSEED compounds\n",
    "    for rxnid in modelseed_rxn_hash:\n",
    "        if \"compound_ids\" in modelseed_rxn_hash[rxnid]:\n",
    "            for cpd in modelseed_rxn_hash[rxnid][\"compound_ids\"]:\n",
    "                modelseed_cpd_hash[cpd][\"reactions\"] += 1 \n",
    "    #Loading ModelSEED compounds into base inchi hash - if collisions occur, keep version with more reactions\n",
    "    #modelseed_cpd_hash[\"cpd00027\"][\"reactions\"] = 10000000000\n",
    "    for cpd in input_data:\n",
    "        if len(cpd[\"baseinchi\"]) > 0:\n",
    "            if cpd[\"baseinchi\"] not in baseinchi_all:\n",
    "                baseinchi_all[cpd[\"baseinchi\"]] = []\n",
    "            baseinchi_all[cpd[\"baseinchi\"]].append(cpd)\n",
    "            if cpd[\"baseinchi\"] in baseinchi_modelseed_hash:\n",
    "                if cpd[\"reactions\"] > baseinchi_modelseed_hash[cpd[\"baseinchi\"]][\"reactions\"]:\n",
    "                    baseinchi_modelseed_hash[cpd[\"baseinchi\"]] = cpd\n",
    "            else:\n",
    "                baseinchi_modelseed_hash[cpd[\"baseinchi\"]] = cpd\n",
    "\n",
    "baseinchi_modelseed_hash[\"WQZGKKKJIJFFOK\"] = modelseed_cpd_hash[\"cpd00027\"]\n",
    "#Printing supplementary data\n",
    "model_compounds = []\n",
    "model_reactions = []\n",
    "compound_hash = {}\n",
    "reaction_hash = {}\n",
    "basemodel = kbase_api.get_object(\"MMSyn3\",29280)\n",
    "basemdl_cpd_hash = {}\n",
    "mdl_rxn_hash = {}\n",
    "mdl_cpd_hash = {}\n",
    "baseinchi_hash = {}\n",
    "for cpd in basemodel[\"modelcompounds\"]:\n",
    "    data = {\n",
    "        \"id\":cpd[\"id\"],\n",
    "        \"name\":cpd[\"name\"],\n",
    "        \"formula\":cpd[\"formula\"],\n",
    "        \"charge\":cpd[\"charge\"],\n",
    "        \"smiles\":cpd[\"smiles\"],\n",
    "        \"inchikey\":cpd[\"inchikey\"],\n",
    "        \"baseinchi\":cpd[\"inchikey\"].split(\"-\")[0],\n",
    "        \"modelseed\":\"\",\n",
    "        \"peaks\":{},\n",
    "        \"flux\":0,\n",
    "        \"generation\":0,\n",
    "        \"reactions\":0,\n",
    "        \"exp_rxns\":0\n",
    "    }\n",
    "    if re.search(\"cpd\\d+\",cpd[\"id\"]):\n",
    "        data[\"modelseed\"] = cpd[\"id\"].split(\"_\")[0]\n",
    "    if cpd[\"id\"] not in compound_hash:\n",
    "        model_compounds.append(cpd[\"id\"])\n",
    "        compound_hash[cpd[\"id\"]] = data\n",
    "        mdl_cpd_hash[cpd[\"id\"]] = data\n",
    "        basemdl_cpd_hash[cpd[\"id\"]] = data\n",
    "for rxn in basemodel[\"modelreactions\"]:\n",
    "    original_id = rxn[\"string_attributes\"][\"original_id\"]\n",
    "    original_id = original_id.replace(\"R_\",\"\")\n",
    "    data = {\n",
    "        \"id\":rxn[\"id\"],\n",
    "        \"modelseed\":\"\",\n",
    "        \"name\":rxn[\"name\"],\n",
    "        \"operators\":[],\n",
    "        \"equation\":\"\",\n",
    "        \"definition\":\"\",\n",
    "        \"generation\":0,\n",
    "        \"flux\":0,\n",
    "        \"genes\":\"\",\n",
    "        \"original_id\":original_id,\n",
    "        \"compounds\":{}\n",
    "    }\n",
    "    model_reactions.append(rxn[\"id\"])\n",
    "    reaction_hash[rxn[\"id\"]] = data\n",
    "    mdl_rxn_hash[rxn[\"id\"]] = data\n",
    "    if re.search(\"rxn\\d+\",rxn[\"id\"]):\n",
    "        data[\"modelseed\"] = rxn[\"id\"].split(\"_\")[0]\n",
    "    if rxn[\"id\"] in flux_hash:\n",
    "        data[\"flux\"] = flux_hash[rxn[\"id\"]]\n",
    "    if \"imported_gpr\" in rxn:\n",
    "        data[\"genes\"] = rxn[\"imported_gpr\"]\n",
    "    for rgt in rxn[\"modelReactionReagents\"]:\n",
    "        cpd_id = rgt[\"modelcompound_ref\"].split(\"/\")[-1]\n",
    "        compound_hash[cpd_id][\"reactions\"] += 1\n",
    "        compound_hash[cpd_id][\"flux\"] += abs(data[\"flux\"])\n",
    "        data[\"compounds\"][cpd_id] = rgt[\"coefficient\"]\n",
    "for cpdid in compound_hash:\n",
    "    cpd = compound_hash[cpdid]\n",
    "    if len(cpd[\"baseinchi\"]) > 0:\n",
    "        if cpd[\"baseinchi\"] not in baseinchi_all:\n",
    "            baseinchi_all[cpd[\"baseinchi\"]] = []\n",
    "        baseinchi_all[cpd[\"baseinchi\"]].append(cpd)\n",
    "        if re.search(\"_e0\",cpdid) == None:\n",
    "            if cpd[\"baseinchi\"] not in baseinchi_hash:\n",
    "                baseinchi_hash[cpd[\"baseinchi\"]] = cpd\n",
    "            elif cpd[\"reactions\"] > baseinchi_hash[cpd[\"baseinchi\"]][\"reactions\"]:\n",
    "                baseinchi_hash[cpd[\"baseinchi\"]] = cpd\n",
    "for biocpd in basemodel[\"biomasses\"][0][\"biomasscompounds\"]:\n",
    "    biocpdid = biocpd[\"modelcompound_ref\"].split(\"/\").pop()\n",
    "    if biocpdid in compound_hash:\n",
    "        compound_hash[biocpdid][\"flux\"] += flux_hash[\"bio1_biomass\"]\n",
    "    else:\n",
    "        print(\"Not found biomass cpd:\"+biocpdid)\n",
    "    \n",
    "#Loading the expansion and adding compounds to the base inchi hash\n",
    "expansion_cpd_hash = {}\n",
    "expansion_rxn_hash = {}\n",
    "expansion_compounds = []\n",
    "expansion_reactions = []\n",
    "expmodel = kbase_api.get_object(\"MMSyn3Expansion\",29280)\n",
    "substitutions = {}\n",
    "for cpd in expmodel[\"modelcompounds\"]:\n",
    "    data = {\n",
    "        \"id\":cpd[\"id\"],\n",
    "        \"name\":cpd[\"name\"],\n",
    "        \"formula\":cpd[\"formula\"],\n",
    "        \"charge\":cpd[\"charge\"],\n",
    "        \"smiles\":cpd[\"smiles\"],\n",
    "        \"inchikey\":cpd[\"inchikey\"],\n",
    "        \"baseinchi\":cpd[\"inchikey\"].split(\"-\")[0],\n",
    "        \"modelseed\":\"\",\n",
    "        \"peaks\":{},\n",
    "        \"generation\":0,\n",
    "        \"flux\":0,\n",
    "        \"exp_rxns\":0,\n",
    "        \"reactions\":0\n",
    "    }\n",
    "    if \"numerical_attributes\" in cpd and \"generation\" in cpd[\"numerical_attributes\"]:\n",
    "        data[\"generation\"] = cpd[\"numerical_attributes\"][\"generation\"]\n",
    "    #Checking if this is a match for an existing compound\n",
    "    if cpd[\"id\"] in basemdl_cpd_hash:\n",
    "        test = 1\n",
    "        #print(cpd[\"id\"])\n",
    "    elif len(data[\"baseinchi\"]) > 0:\n",
    "        if data[\"baseinchi\"] in baseinchi_hash:\n",
    "            data = baseinchi_hash[data[\"baseinchi\"]]\n",
    "            substitutions[cpd[\"id\"]] = data[\"id\"]\n",
    "            print(\"Previous cpd match:\"+cpd[\"id\"]+\";\"+substitutions[cpd[\"id\"]])\n",
    "        elif data[\"baseinchi\"] in baseinchi_modelseed_hash:\n",
    "            #This is a new compound, but it is a match for the modelseed\n",
    "            data[\"id\"] = baseinchi_modelseed_hash[data[\"baseinchi\"]][\"id\"]+\"_c0\"\n",
    "            data[\"modelseed\"] = baseinchi_modelseed_hash[data[\"baseinchi\"]][\"id\"]\n",
    "            substitutions[cpd[\"id\"]] = data[\"id\"]\n",
    "            #print(\"ModelSEED cpd match:\"+cpd[\"id\"]+\";\"+substitutions[cpd[\"id\"]])\n",
    "        if data[\"baseinchi\"] not in baseinchi_hash:\n",
    "            baseinchi_hash[data[\"baseinchi\"]] = data\n",
    "        if data[\"baseinchi\"] not in baseinchi_all:\n",
    "            baseinchi_all[data[\"baseinchi\"]] = []\n",
    "        if data not in baseinchi_all[data[\"baseinchi\"]]:\n",
    "            baseinchi_all[data[\"baseinchi\"]].append(data)\n",
    "    #Adding compound expanded compound hash\n",
    "    if data[\"id\"] not in expansion_cpd_hash:\n",
    "        expansion_cpd_hash[data[\"id\"]] = data\n",
    "        expansion_compounds.append(data[\"id\"])\n",
    "    #Adding compound to all compound hash\n",
    "    if data[\"id\"] not in compound_hash:\n",
    "        compound_hash[data[\"id\"]] = data\n",
    "for rxn in expmodel[\"modelreactions\"]:\n",
    "    gen = 0\n",
    "    if \"generation\" in rxn[\"numerical_attributes\"]:\n",
    "        gen = rxn[\"numerical_attributes\"][\"generation\"]\n",
    "    data = {\n",
    "        \"id\":rxn[\"id\"],\n",
    "        \"name\":rxn[\"name\"],\n",
    "        \"operators\":[],\n",
    "        \"equation\":\"\",\n",
    "        \"definition\":\"\",\n",
    "        \"generation\":gen,\n",
    "        \"flux\":0,\n",
    "        \"compounds\":{},\n",
    "        \"genes\":\"\"\n",
    "    }\n",
    "    reaction_hash[rxn[\"id\"]] = data\n",
    "    expansion_rxn_hash[rxn[\"id\"]] = data\n",
    "    expansion_reactions.append(data[\"id\"])\n",
    "    if \"dblinks\" in rxn and \"PickAxe\" in rxn[\"dblinks\"]:\n",
    "        for op in rxn[\"dblinks\"][\"PickAxe\"]:\n",
    "            op = op.replace(\"enzymatic.\",\"\")\n",
    "            op = op.replace(\"spontaneous.\",\"\")\n",
    "            data[\"operators\"].append(op)\n",
    "    if rxn[\"id\"] in flux_hash:\n",
    "        data[\"flux\"] = flux_hash[rxn[\"id\"]]\n",
    "        model_reactions.append(rxn[\"id\"])\n",
    "        mdl_rxn_hash[rxn[\"id\"]] = data\n",
    "    for rgt in rxn[\"modelReactionReagents\"]:\n",
    "        cpd_id = rgt[\"modelcompound_ref\"].split(\"/\")[-1]\n",
    "        if cpd_id in substitutions:\n",
    "            cpd_id = substitutions[cpd_id]\n",
    "        compound_hash[cpd_id][\"exp_rxns\"] += 1\n",
    "        data[\"compounds\"][cpd_id] = rgt[\"coefficient\"]\n",
    "        if rxn[\"id\"] in flux_hash:\n",
    "            compound_hash[cpd_id][\"flux\"] += abs(data[\"flux\"])\n",
    "            if cpd_id not in mdl_cpd_hash:\n",
    "                mdl_cpd_hash[cpd_id] = compound_hash[cpd_id]\n",
    "                model_compounds.append(cpd_id)\n",
    "        \n",
    "#Adding ModelSEED reactions and compounds with flux\n",
    "model_rxn = 0\n",
    "ms_rxn = 0\n",
    "for rxn in flux_hash:\n",
    "    if abs(flux_hash[rxn]) > 0:\n",
    "        if rxn in mdl_rxn_hash:\n",
    "            model_rxn += 1\n",
    "        elif rxn not in mdl_rxn_hash and rxn in modelseed_rxn_hash:\n",
    "            ms_rxn += 1\n",
    "            data = {\n",
    "                \"id\":rxn,\n",
    "                \"name\":modelseed_rxn_hash[rxn][\"name\"],\n",
    "                \"operators\":[],\n",
    "                \"equation\":\"\",\n",
    "                \"definition\":\"\",\n",
    "                \"generation\":0,\n",
    "                \"flux\":flux_hash[rxn],\n",
    "                \"genes\":\"\",\n",
    "                \"compounds\":{},\n",
    "                \"modelseed\":rxn,\n",
    "                \"kbase_id\":rxn\n",
    "            }\n",
    "            reaction_hash[rxn] = data\n",
    "            model_reactions.append(rxn)\n",
    "            mdl_rxn_hash[rxn] = data\n",
    "            for item in modelseed_rxn_hash[rxn][\"stoichiometry\"]:\n",
    "                array = item.split(\":\")\n",
    "                cpd = array[1]\n",
    "                suffix = \"_c0\"\n",
    "                if array[2] == \"1\":\n",
    "                    suffix = \"_e0\"\n",
    "                cpdid = cpd+suffix\n",
    "                if cpdid in substitutions:\n",
    "                    cpdid = substitutions[cpdid]\n",
    "                data[\"compounds\"][cpdid] = float(array[0])\n",
    "                if cpdid not in compound_hash:\n",
    "                    cpddata = {\n",
    "                        \"id\":cpdid,\n",
    "                        \"name\":modelseed_cpd_hash[cpd][\"name\"]+suffix,\n",
    "                        \"formula\":modelseed_cpd_hash[cpd][\"formula\"],\n",
    "                        \"charge\":modelseed_cpd_hash[cpd][\"charge\"],\n",
    "                        \"inchikey\":\"\",\n",
    "                        \"baseinchi\":\"\",\n",
    "                        \"modelseed\":cpd,\n",
    "                        \"peaks\":{},\n",
    "                        \"flux\":0,\n",
    "                        \"reactions\":0\n",
    "                    }\n",
    "                    if \"inchikey\" in modelseed_cpd_hash[cpd]:\n",
    "                        cpddata[\"inchikey\"] = modelseed_cpd_hash[cpd][\"inchikey\"]\n",
    "                        cpddata[\"baseinchi\"] = modelseed_cpd_hash[cpd][\"inchikey\"].split(\"-\")[0]\n",
    "                    compound_hash[cpdid] = cpddata\n",
    "                compound_hash[cpdid][\"reactions\"] += 1\n",
    "                compound_hash[cpdid][\"flux\"] += abs(flux_hash[rxn])\n",
    "                if cpdid not in mdl_cpd_hash:\n",
    "                    mdl_cpd_hash[cpdid] = compound_hash[cpdid]\n",
    "                    model_compounds.append(cpdid)\n",
    "        #else:\n",
    "            #print(\"No match:\"+rxn)\n",
    "            \n",
    "#Loading metabolomics, matching to the ModelSEED, matching to the model, matching to the expansion, and printing\n",
    "peaks = []\n",
    "metabolomics = kbase_api.get_from_ws(\"JCVI_Syn3_metabolomics\",29280)\n",
    "fluxcount = 0\n",
    "peaks_found = {}\n",
    "peak_active = 0\n",
    "for peak in metabolomics.peaks:\n",
    "    data = {\n",
    "        \"id\":peak.id,\n",
    "        \"name\":peak.attributes[\"name\"],\n",
    "        \"rt\":peak.attributes[\"retention_time\"],\n",
    "        \"mz\":peak.attributes[\"aggregate_mz\"],\n",
    "        \"polarity\":peak.attributes[\"polarity\"],\n",
    "        \"formula\":peak.attributes[\"formula\"],\n",
    "        \"smiles\":peak.attributes[\"smiles\"],\n",
    "        \"inchikey\":peak.attributes[\"inchikey\"],\n",
    "        \"modelseed_compounds\":{},\n",
    "        \"model_compounds\":{},\n",
    "        \"expansion_compounds\":{},\n",
    "        \"flux\":0,\n",
    "        \"solution\":0\n",
    "    }\n",
    "    peaks_found[peak.id] = 1\n",
    "    if peak.id in peak_solution_hash:\n",
    "        data[\"solution\"] = 1\n",
    "        peak_active += 1\n",
    "    peaks.append(data)\n",
    "    if len(data[\"inchikey\"]) > 0:\n",
    "        baseinchi = data[\"inchikey\"].split(\"-\")[0]\n",
    "        if baseinchi in baseinchi_all:\n",
    "            for cpd in baseinchi_all[baseinchi]:\n",
    "                cpdid = cpd[\"id\"]\n",
    "                cpdid = cpdid.replace(\"_c0\",\"\")\n",
    "                cpdid = cpdid.replace(\"_e0\",\"\")\n",
    "                if cpdid+\"_c0\" in compound_hash:\n",
    "                    cpd = compound_hash[cpdid+\"_c0\"]\n",
    "                cpd[\"peaks\"][data[\"id\"]] = 1\n",
    "                if \"flux\" in cpd:\n",
    "                    data[\"flux\"] += abs(cpd[\"flux\"])\n",
    "                if cpdid in modelseed_cpd_hash:\n",
    "                    data[\"modelseed_compounds\"][cpdid] = 1\n",
    "                if cpdid+\"_c0\" in basemdl_cpd_hash:\n",
    "                    data[\"model_compounds\"][cpdid] = 1\n",
    "                if cpdid+\"_c0\" in expansion_cpd_hash:\n",
    "                    data[\"expansion_compounds\"][cpdid] = 1\n",
    "    if data[\"flux\"] > 0:\n",
    "        fluxcount += 1\n",
    "print(\"Flux count:\"+str(fluxcount))\n",
    "print(\"Active peak count:\"+str(peak_active))\n",
    "\n",
    "for peak in peak_solution_hash:\n",
    "    if peak not in peaks_found:\n",
    "        print(\"Peak not found:\"+peak)\n",
    "\n",
    "#Building reaction equations\n",
    "for rxn in reaction_hash:\n",
    "    data = reaction_hash[rxn]\n",
    "    new_hash = {}\n",
    "    products = \"\"\n",
    "    def_products = \"\"\n",
    "    for cpdid in data[\"compounds\"]:\n",
    "        cpddata = compound_hash[cpdid]\n",
    "        if data[\"compounds\"][cpdid] < 0:\n",
    "            if len(data[\"equation\"]) > 0:\n",
    "                data[\"equation\"] += \" + \"\n",
    "                data[\"definition\"] += \" + \"\n",
    "            if data[\"compounds\"][cpdid] != -1:\n",
    "                data[\"equation\"] += \"(\"+str(-1*data[\"compounds\"][cpdid])+\") \"\n",
    "                data[\"definition\"] += \"(\"+str(-1*data[\"compounds\"][cpdid])+\") \"    \n",
    "            data[\"equation\"] += cpddata[\"id\"]\n",
    "            data[\"definition\"] += cpddata[\"name\"]\n",
    "        elif data[\"compounds\"][cpdid] > 0:\n",
    "            if len(products) > 0:\n",
    "                products += \" + \"\n",
    "                def_products += \" + \"\n",
    "            if data[\"compounds\"][cpdid] != 1:\n",
    "                products += \"(\"+str(data[\"compounds\"][cpdid])+\") \"\n",
    "                def_products += \"(\"+str(data[\"compounds\"][cpdid])+\") \"\n",
    "            products += cpddata[\"id\"]\n",
    "            def_products += cpddata[\"name\"]\n",
    "    data[\"equation\"] += \" => \"+products\n",
    "    data[\"definition\"] += \" => \"+def_products                   \n",
    "  \n",
    "#Loading COBRA model and swapping out missed compound matches\n",
    "model= cobra.io.load_json_model(\"JCVISyn3Exp-cobrapy_model.json\")\n",
    "met_rep = {}\n",
    "remove_list = []\n",
    "for metabolite in substitutions:\n",
    "    if metabolite in model.metabolites:\n",
    "        met = model.metabolites.get_by_id(metabolite)\n",
    "        if substitutions[metabolite] in model.metabolites:\n",
    "            rep = model.metabolites.get_by_id(substitutions[metabolite])\n",
    "            met_rep[met] = rep\n",
    "            remove_list.append(met)\n",
    "for reaction in model.reactions:\n",
    "    for met in met_rep:\n",
    "        if met in reaction.metabolites:\n",
    "            reaction.add_metabolites({met_rep[met]:reaction.metabolites[met]},combine=True)    \n",
    "model.remove_metabolites(remove_list,False)\n",
    "\n",
    "#Printing final data\n",
    "file = open(\"JCVISyn3Exp_model_reactions.tsv\",\"w\") \n",
    "file.write(\"Reaction ID\\tName\\tOperators\\tEquation\\tDefinition\\tGenes\\tFlux\\n\")\n",
    "columns = [\"name\",\"operators\",\"equation\",\"definition\",\"genes\",\"flux\"]\n",
    "for rxnid in model_reactions:\n",
    "    item = reaction_hash[rxnid]\n",
    "    item[\"operators\"] = \", \".join(item[\"operators\"])\n",
    "    line = item[\"id\"]\n",
    "    item[\"flux\"] = str(item[\"flux\"])\n",
    "    for column in columns:\n",
    "            line += \"\\t\"\n",
    "            if column in item:\n",
    "                line += item[column]\n",
    "    file.write(line+\"\\n\")\n",
    "file.close()\n",
    "\n",
    "file = open(\"JCVISyn3Exp_model_compounds.tsv\",\"w\") \n",
    "file.write(\"Compound ID\\tName\\tFormula\\tCharge\\tSmiles\\tInchikey\\tModelSEED\\tPeaks\\tFlux\\n\")\n",
    "columns = [\"name\",\"formula\",\"charge\",\"smiles\",\"inchikey\",\"modelseed\",\"peaks\",\"flux\"]\n",
    "for cpdid in model_compounds:\n",
    "    item = compound_hash[cpdid]\n",
    "    line = item[\"id\"]  \n",
    "    item[\"peaks\"] = \", \".join(item[\"peaks\"].keys())\n",
    "    item[\"flux\"] = str(item[\"flux\"])\n",
    "    item[\"charge\"] = str(item[\"charge\"])\n",
    "    for column in columns:\n",
    "            line += \"\\t\"\n",
    "            if column in item:\n",
    "                line += item[column]\n",
    "    file.write(line+\"\\n\")\n",
    "file.close()\n",
    "    \n",
    "file = open(\"JCVISyn3_full_expansion_reactions.tsv\",\"w\") \n",
    "file.write(\"Reaction ID\\tName\\tOperators\\tEquation\\tDefinition\\tGeneration\\n\")\n",
    "columns = [\"name\",\"operators\",\"equation\",\"definition\",\"generation\"]\n",
    "for rxnid in expansion_reactions:\n",
    "    item = reaction_hash[rxnid]\n",
    "    item[\"operators\"] = \", \".join(item[\"operators\"])\n",
    "    line = item[\"id\"]\n",
    "    item[\"generation\"] = str(item[\"generation\"])\n",
    "    for column in columns:\n",
    "            line += \"\\t\"\n",
    "            if column in item:\n",
    "                line += item[column]\n",
    "    file.write(line+\"\\n\")\n",
    "file.close()\n",
    "    \n",
    "file = open(\"JCVISyn3_full_expansion_compounds.tsv\",\"w\") \n",
    "file.write(\"Compound ID\\tName\\tFormula\\tCharge\\tSmiles\\tInchikey\\tModelSEED\\tPeaks\\tGeneration\\n\")\n",
    "columns = [\"name\",\"formula\",\"charge\",\"smiles\",\"inchikey\",\"modelseed\",\"peaks\",\"generation\"]\n",
    "for cpdid in expansion_compounds:\n",
    "    item = compound_hash[cpdid]\n",
    "    line = item[\"id\"]\n",
    "    if not isinstance(item[\"charge\"], str):\n",
    "        item[\"charge\"] = str(item[\"charge\"])\n",
    "    if not isinstance(item[\"generation\"], str):\n",
    "        item[\"generation\"] = str(item[\"generation\"])\n",
    "    if not isinstance(item[\"peaks\"], str):\n",
    "        item[\"peaks\"] = \", \".join(item[\"peaks\"].keys())\n",
    "    for column in columns:\n",
    "            line += \"\\t\"\n",
    "            if column in item:\n",
    "                line += item[column]\n",
    "    file.write(line+\"\\n\")\n",
    "file.close()\n",
    "    \n",
    "file = open(\"JCVISyn3_peaks.tsv\",\"w\") \n",
    "file.write(\"Peak ID\\tName\\tRT\\tM/Z\\tPolarity\\tFormula\\tSmiles\\tInchikey\\tModelSEED compounds\\tModel compounds\\tExpansion compounds\\tFlux\\tSolution\\n\")\n",
    "columns = [\"name\",\"rt\",\"mz\",\"polarity\",\"formula\",\"smiles\",\"inchikey\",\"modelseed_compounds\",\"model_compounds\",\"expansion_compounds\",\"flux\",\"solution\"]\n",
    "for item in peaks:\n",
    "    line = item[\"id\"]\n",
    "    item[\"modelseed_compounds\"] = \", \".join(item[\"modelseed_compounds\"].keys())\n",
    "    item[\"model_compounds\"] = \", \".join(item[\"model_compounds\"].keys())\n",
    "    item[\"expansion_compounds\"] = \", \".join(item[\"expansion_compounds\"].keys())\n",
    "    item[\"flux\"] = str(item[\"flux\"])\n",
    "    item[\"solution\"] = str(item[\"solution\"])\n",
    "    for column in columns:\n",
    "            line += \"\\t\"\n",
    "            if column in item:\n",
    "                line += item[column]\n",
    "    file.write(line+\"\\n\")\n",
    "file.close()\n",
    "    \n",
    "#Print SBML\n",
    "modelseed = cobrakbase.modelseed.from_local('/Users/chenry/code/ModelSEEDDatabase')\n",
    "cobrakbase.annotate_model_with_modelseed(model, modelseed)\n",
    "filename = \"JCVISyn3Exp_model.xml\"\n",
    "cobra.io.write_sbml_model(model,filename)\n",
    "filename = \"JCVISyn3Exp_model.json\"\n",
    "cobra.io.save_json_model(model,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-51-b7ba028d2426>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-51-b7ba028d2426>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    print(\"ModelSEED ID mismatch:\"+baseinchi_modelseed_hash[data[\"baseinchi\"][\"id\"]+\";\"+cpd[\"id\"])\u001b[0m\n\u001b[0m                                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "if len(data[\"inchikey\"]) > 0:\n",
    "        if cpd[\"id\"] not in mdl_id_hash:\n",
    "            #First check if this compound matches an existing compound\n",
    "            if data[\"baseinchi\"] in baseinchi_hash:\n",
    "                replacements[cpd[\"id\"]] =  baseinchi_hash[data[\"baseinchi\"]][\"id\"]\n",
    "            else:\n",
    "                baseinchi_hash[data[\"baseinchi\"]] = data\n",
    "                baseinchi_expansion_hash[data[\"baseinchi\"]] = data\n",
    "                expansion_compounds.append(data)\n",
    "                compound_hash[cpd[\"id\"]] = data\n",
    "                #Checking if this compound matches the ModelSEED\n",
    "                if data[\"baseinchi\"] in baseinchi_modelseed_hash:\n",
    "                    data[\"modelseed\"] = baseinchi_modelseed_hash[data[\"baseinchi\"][\"id\"]\n",
    "                    if baseinchi_modelseed_hash[data[\"baseinchi\"][\"id\"] != cpd[\"id\"]:\n",
    "                        print(\"ModelSEED ID mismatch:\"+baseinchi_modelseed_hash[data[\"baseinchi\"][\"id\"]+\";\"+cpd[\"id\"])\n",
    "        else:\n",
    "            baseinchi_expansion_hash[data[\"baseinchi\"]] = compound_hash[cpd[\"id\"]]\n",
    "            expansion_compounds.append(compound_hash[cpd[\"id\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
